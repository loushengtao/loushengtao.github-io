<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>1st&#39;s stdio</title>
  
  <subtitle>never say never</subtitle>
  <link href="https://loushengtao.github.io/atom.xml" rel="self"/>
  
  <link href="https://loushengtao.github.io/"/>
  <updated>2022-04-07T09:45:04.906Z</updated>
  <id>https://loushengtao.github.io/</id>
  
  <author>
    <name>Levite.Lou</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pytorch推理相关</title>
    <link href="https://loushengtao.github.io/2022/04/73edeb87/"/>
    <id>https://loushengtao.github.io/2022/04/73edeb87/</id>
    <published>2022-04-06T16:15:39.000Z</published>
    <updated>2022-04-07T09:45:04.906Z</updated>
    
    <content type="html"><![CDATA[<p><link href="https://cdn.bootcss.com/highlight.js/8.0/styles/brown_paper.min.css" rel="stylesheet"></p><script src="https://cdn.bootcss.com/highlight.js/8.0/highlight.min.js"></script><script>    hljs.initHighlightingOnLoad();</script><blockquote><p>理论上来说，掌握了如何推理，可以算是个披着狼皮的高级人工智能工程师了——(你虽然不懂原理，但你会用啊，打肿脸充胖子总是可以的)，OK，那接下来就来讲一下，Pytorch应该如何推理</p></blockquote><pre><code>int main():</code></pre><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">int a;<br>double o<br><br>typedef struct a&#123;<br>    int a;<br>    double b;<br>&#125;<br>string a;  // 试一试注释<br><br>printf(asda)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(a)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;link href=&quot;https://cdn.bootcss.com/highlight.js/8.0/styles/brown_paper.min.css&quot; rel=&quot;stylesheet&quot;&gt;&lt;/p&gt;
&lt;script src=&quot;https://cdn.bootcss.</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>树莓派视觉小车项目</title>
    <link href="https://loushengtao.github.io/2022/03/df0945ec/"/>
    <id>https://loushengtao.github.io/2022/03/df0945ec/</id>
    <published>2022-03-31T06:13:58.000Z</published>
    <updated>2022-04-06T16:15:21.005Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近学校里的自动化学院举办了电设院赛，有一个组别是包含视觉的控制组，作为稚晖军的粉丝，当然是要全栈做一辆视觉小车了，这是我自己全栈制作的第一个项目，本着巩固学习的目的，在此开博记录一下自己的学习与制作历程</p></blockquote><h2 id="制作数据集">制作数据集</h2><p>采用摄像头拍摄并制作自己的数据集</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;最近学校里的自动化学院举办了电设院赛，有一个组别是包含视觉的控制组，作为稚晖军的粉丝，当然是要全栈做一辆视觉小车了，这是我自己全栈制作的第一个项目，本着巩固学习的目的，在此开博记录一下自己的学习与制作历程&lt;/p&gt;
&lt;/blockquote&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>蓝牙模块通信</title>
    <link href="https://loushengtao.github.io/2022/03/27a8e7c6/"/>
    <id>https://loushengtao.github.io/2022/03/27a8e7c6/</id>
    <published>2022-03-29T07:00:09.000Z</published>
    <updated>2022-03-29T09:16:33.834Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>AboutConvolution</title>
    <link href="https://loushengtao.github.io/2022/03/95dd147c/"/>
    <id>https://loushengtao.github.io/2022/03/95dd147c/</id>
    <published>2022-03-29T03:33:18.000Z</published>
    <updated>2022-04-01T09:50:55.206Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于卷积">关于“卷”积</h1><h2 id="卷积的本质">1.卷积的本质</h2><p>在数学中的泛函分析中，卷积也叫做旋积或者褶积，是一种通过两个函数x(t)和h(t)生成的数学算子。其计算公式如下：</p><p><spanclass="math display">\[连续形式：x(t)*h(t)=\int_{-\infty}^{\infty}x(\tau)h(t-\tau)dt\]</span></p><p><spanclass="math display">\[离散形式：x(t)*h(t)=\sum_{t=-\infty}^{\infty}x(\tau)h(t-\tau)\quad\]</span></p><p>从公式来看，卷积就是先将函数进行一个翻转(Reverse)，然后再做一个平移(Shift)，<strong>这便是卷的含义</strong>。而积就是将平移后的两个函数对应元素相乘求和。所以卷积本质上就是<span class="math display">\[Reverse-Shift-Weighted\quadSummation\]</span></p><p>我们可以用图像来描述卷积的过程：</p><p><img src="\assets\BlogPic\AboutConvolution1.png"></p><h2 id="单通道卷积与多通道卷积">2. 单通道卷积与多通道卷积</h2><p>卷积之后的通道数周四只是取决于卷积核的数目，核卷积核的channel无关，卷积核的channel是和输入的channel保持一致的</p><h3 id="单通道卷积">2.1 单通道卷积</h3><p>顾名思义，单通道卷积即输入为单通道，卷积核也为单通道，单通道卷积的理解是图像卷积的基础</p><h3 id="多通道卷积">2.2 多通道卷积</h3><p>多通道卷积可以分为<strong>常规卷积</strong>和<strong>深度可分离卷积</strong>，两者的区别在于参数数量，我们知道在深度卷积网络训练的过程中过多的参数会增大网络计算量，不利于网络模型泛化等缺点，而深度可分离卷积在实现常规卷积的基础上减少了网络参数。</p><h4 id="常规卷积">常规卷积</h4><p>常规的多通道卷积和单通道卷积类似，区别在于在多通道卷积中，卷积核和输入的图像同样都是多通道的，结果的通道数等同于卷积核的数量。</p><p><img src="\assets\BlogPic\AboutConvolution2.png"></p><p>如图所示，多通道常规卷积的基本步骤可以分为以下三点：</p><ul><li>每个卷积核对应结果的一层通道</li><li>卷积核的每一层与输入图像的每一层进行卷积，最后将结果相加，作为卷积核结果层的数据</li><li>得到一层结果数据后，换下一个卷积核进行运算</li></ul><blockquote><p>这里要区分<strong>卷积核数目</strong>和<strong>通道数目以及最后生成的</strong>featuremap**的通道数量</p></blockquote><h4 id="times1卷积"><spanclass="math inline">\(1\times1\)</span>卷积</h4><p><span class="math inline">\(1\times1\)</span>卷积是大小为<spanclass="math inline">\(1\times1\)</span>的滤波器做卷积操作，多用于d多通道卷积，主要作用为改变通道数目。这里附上吴恩达老师的课件截图：</p><p><img src="\assets\BlogPic\AboutConvolution3.png"></p><blockquote><p>个人感觉<spanclass="math inline">\(1\times1\)</span>的本质相当于做了一次亚全连接，改变了通道数，缩小了计算量。</p></blockquote><h3 id="深度可分离卷积">深度可分离卷积</h3><p>深度可分离卷积的方法与常规卷积的方法有所不同，正常的卷积核是对多个通道同时做卷积。也就是说，多个通道在一次卷积后输出一个数。</p><p>而深度可分离卷积则不同，深度可分离卷积分为两步：</p><ul><li>第一步用卷积核的n层分别与对应通道做卷积，在这样一次卷积后，输出n层。</li><li>这样输出的n层，再通过一个<span class="math inline">\(1\times1\timesn\)</span>的卷积核(pointwise核)卷积，得到一个数。</li></ul><p>用图片来表示深度可分离卷积的过程：</p><p>第一步，对n个层分别做卷积，输出n个通道的数据</p><p><img src="\assets\BlogPic\AboutConvolution4.png"></p><p>第二步，用卷积核对<span class="math inline">\(1\times1\timesn\)</span>对多个通道数据再次做卷积运算，这个时候的输出就和正常卷积一样，是单通道的数据</p><p><img src="\assets\BlogPic\AboutConvolution5.png"></p><p>如果要提取更多属性，则只需设计更多的<spanclass="math inline">\(1\times1\timesn\)</span>的卷积核就行，不同参数的卷积核可以提取不同的特征。</p><p><img src="\assets\BlogPic\AboutConvolution6.png"></p><p>这里简单分析一下深度可分离卷积与标准卷积在计算量上的差别。假定输入的特征图大小是<spanclass="math inline">\(D_{f}\times D_{F}\timesM\)</span>，而输出特征图的大小是<span class="math inline">\(D_{F}\timesD_{F}\times N\)</span>。</p><p>参数如下：</p><ul><li>输入图像尺寸：<span class="math inline">\(D_{F}\times D_{F}\timesM\)</span></li><li>输出图像尺寸：<span class="math inline">\(D_{F}\times D_{F}\timesN\)</span></li><li>逐层卷积核尺寸：<span class="math inline">\(D_{K}\times D_{K}\timesM\)</span></li><li><span class="math inline">\(1\times1\)</span>卷积核个数：<spanclass="math inline">\(N\)</span> (个数等于输出图像通道数)</li></ul><p>对于标准的卷积<span class="math inline">\(D_{K}\timesD{K}\)</span>，其计算量将是：</p><p><span class="math display">\[D_{K}\times D_{K}\times M\times N\timesD_{F}\times D_{F}\]</span></p><p>而对于深度可分离卷积，可以将计算量分为两个部分：</p><ul><li>逐层卷积：<span class="math inline">\(D_{F}\times D_{F}\timesD_{K}\times D_{K}\timesM\)</span>——(输入大小乘卷积核大小乘通道数)。</li><li><span class="math inline">\(1\times1\)</span>的逐点卷积：<spanclass="math inline">\(D_{F}\times D_{F}\times M\timesN\)</span>——(输出大小乘输入通道数乘<spanclass="math inline">\(1\times1\)</span>卷积核个数)</li></ul><p>综上所述，深度可分离卷积的计算量为：</p><p><span class="math display">\[D_{F}\times D_{F}\times D_{K}\timesD_{K}\times M+D_{F}\times D_{F}\times M\times N\]</span></p><p>可以比较深度可分离卷积核和标准卷积的计算量如下:</p><p><span class="math display">\[\frac{O_{DSC}}{O_{SC}}=\frac{D_{F}\timesD_{F}\times D_{K}\times D_{K}\times M+D_{F}\times D_{F}\times M\timesN}{D_{K}\times D_{K}\times M\times N\times D_{F}\timesD_{F}}\]</span></p><blockquote><p><span class="math inline">\(DSC: Depth SeparableConvolution\quad\)</span> <span class="math inline">\(SC: StanderedConvolution\)</span></p></blockquote><h2 id="d2d和3d卷积">3. 1D,2D和3D卷积</h2><h3 id="d卷积多用于频谱1维">3.1 1D卷积——多用于频谱——1维</h3><p>一维卷积通常用于实践序列的数据分析(因为这种情况下的输入为1D）。</p><p><img src="\assets\BlogPic\AboutConvolution7.png"></p><p>一维数据的输入可以具有多个通道，但是滤波器智能沿一个方向运动，因此输出为1D</p><h3 id="d卷积多用于图像2维">3.2 2D卷积——多用于图像——2维</h3><p>2D卷积有分为<strong>单通道卷积</strong>和<strong>多通道卷积</strong>，二者在本质上并无太大的差异。</p><p><img src="\assets\BlogPic\AboutConvolution8.gif"></p><h3 id="d卷积多用于视频3维">3.3 3D卷积——多用于视频——3维</h3><p>将2D卷积增加一个深度维便扩展为3D卷积，输入的图像是3维的，滤波器也是3维的，对应的卷积输出同样是3维的。3D的卷积操作同样分为单通道和多通道，且只使用一个filter，输出一个channel。</p><ul><li>其中，针对单通道，与2D卷积的不同之处在于输入图像多了一个depth维度，故输入大小为(1,depth,height,width)，卷积核也多了一个k_d维度，因此卷积核在输入图像的空间维度(height和width)和深度维度depth维度上均进行滑窗操作，每次滑窗得到输出3D图像的一个value。</li></ul><p><img src="\assets\BlogPic\AboutConvolution9.png"></p><ul><li>针对多通道，则就是在输出value时将值相加即可</li></ul><p><img src="\assets\BlogPic\AboutConvolution10.png"></p><blockquote><p>相比于2D卷积，3D卷积可以提取连续帧之间的运动信息。</p></blockquote><h2 id="deconvolution">4.Deconvolution</h2><p>大多数将Deconvolution翻译为转置卷积，那是从Deconvolution的数学原理出发，我更愿意称之为反卷积，也就是卷积的逆过程。反卷积是一种上采样(up-sampling)的常见方法。</p><p>本质上来说，反卷积跟常规卷积并无区别。不同之处在于在反卷积时，卷积核将会根据一定比例的padding来扩大输入尺寸，然后把常规卷积中的卷积核进行转置。</p><p>假设输入的图像矩阵为X，卷积核矩阵为C，常规卷积的输出为Y，则有：</p><p><span class="math display">\[Y=CX\]</span></p><p>两边同时乘以卷积核的转置<spanclass="math inline">\(C^{T}\)</span>，这个公式便是反卷积的输入输出计算：</p><p><span class="math display">\[X=C^{T}Y\]</span></p><p>图示过程如下：</p><p><img src="\assets\BlogPic\AboutConvolution11.png"></p><p><img src="\assets\BlogPic\AboutConvolution12.png"></p><p>参考资料：</p><p>[1] <ahref="https://blog.csdn.net/StardustYu/article/details/104618100?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164852668216780269859203%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=164852668216780269859203&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-1-104618100.142%5Ev5%5Epc_search_result_control_group,143%5Ev6%5Econtrol&amp;utm_term=%E5%90%84%E7%A7%8D%E5%8D%B7%E7%A7%AF%E6%96%B9%E5%BC%8F&amp;spm=1018.2226.3001.4187">深度学习知识系列(二)各种卷积形式</a></p><p>[2] <ahref="https://blog.csdn.net/w1995s/article/details/116378190?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%90%84%E7%A7%8D%E5%8D%B7%E7%A7%AF%E6%96%B9%E5%BC%8F&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-116378190.142%5Ev5%5Epc_search_result_control_group,143%5Ev6%5Econtrol&amp;spm=1018.2226.3001.4187">各种卷积方式</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;关于卷积&quot;&gt;关于“卷”积&lt;/h1&gt;
&lt;h2 id=&quot;卷积的本质&quot;&gt;1.卷积的本质&lt;/h2&gt;
&lt;p&gt;在数学中的泛函分析中，卷积也叫做旋积或者褶积，是一种通过两个函数x(t)和h(t)生成的数学算子。其计算公式如下：&lt;/p&gt;
&lt;p&gt;&lt;span
class=&quot;m</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>树莓派</title>
    <link href="https://loushengtao.github.io/2022/03/140ab620/"/>
    <id>https://loushengtao.github.io/2022/03/140ab620/</id>
    <published>2022-03-22T15:30:00.000Z</published>
    <updated>2022-04-07T05:41:47.432Z</updated>
    
    <content type="html"><![CDATA[<h3id="最近刚和同学入手了一个树莓派在此开一个博客记录一下自己树莓派的操作历程">最近刚和同学入手了一个树莓派，在此开一个博客记录一下自己树莓派的操作历程。</h3><h1 id="树莓派的基本配置">1.树莓派的基本配置</h1><h2 id="系统">1.1 系统</h2><p>树莓派可以运行各种系统，我这里使用的是树莓派的专属系统Raspbery，直接在官网下载即可</p><p>具体操作：</p><pre><code>* 打开下载页面https://www.raspberrypi.org/downloads/* 下载官网提供的exe文件* 通过官网的exe文件进行烧录</code></pre><h1 id="显示器">1.2 显示器</h1><p>对应不同的显示器需要在树莓派里安装不同的驱动，官网下载的树莓派系统里默认安装的是传统HDMI显示器。</p><p>如果想要在别的屏幕上显示，例如7寸显示屏，则需要安装7寸显示屏的驱动，可以使用系统用户命令行安装</p><ul><li><p>获取LCD驱动 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">git clone https://github.com/goodtft/LCD-show.git<br>chmod -R 755 LCD-show<br>cd LCD-show/<br></code></pre></td></tr></table></figure></p></li><li><p>安装LCD驱动 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">若要使用7寸C款1024*600则对应执行：<br>sudo ./LCD7C-show<br>若要切换回传统的HDMI显示器则对应执行：<br>sudo ./LCD-hdmi<br></code></pre></td></tr></table></figure>若用上述命令切换显示，则执行完命令之后就无法在当前屏幕上显示，只需切换到命令指定的显示器执行即可。</p></li></ul><p>也可用树莓派的SPI接口的屏幕，驱动与传统HDMI驱动相同</p><h1 id="python环境">2.python环境</h1><p>我这里是在<ahref="https://www.raspberrypi.org/downloads/">https://www.raspberrypi.org/downloads/</a>树莓派官方安装界面烧录的系统，首先先看看树莓派系统有没有自己装python：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">pi@raspberrypi:~ $ python<br>Python 3.9.2 (default, Mar 12 2021 04:06:34)<br>[GCC 10.2.1 20210110] on linux<br>Type &quot;&quot;<br></code></pre></td></tr></table></figure><p>很好，发现树莓派安装的最新系统自带了python 3.9.2,那么接下来再看看有没有配套的pip</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3
id=&quot;最近刚和同学入手了一个树莓派在此开一个博客记录一下自己树莓派的操作历程&quot;&gt;最近刚和同学入手了一个树莓派，在此开一个博客记录一下自己树莓派的操作历程。&lt;/h3&gt;
&lt;h1 id=&quot;树莓派的基本配置&quot;&gt;1.树莓派的基本配置&lt;/h1&gt;
&lt;h2 id=&quot;系统&quot;&gt;1.1</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>论文写作技巧</title>
    <link href="https://loushengtao.github.io/2022/03/b17e5bc4/"/>
    <id>https://loushengtao.github.io/2022/03/b17e5bc4/</id>
    <published>2022-03-21T11:36:42.000Z</published>
    <updated>2022-03-21T11:43:10.430Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常用语句">常用语句</h2><p><code>"To the best of our knowledge"</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;常用语句&quot;&gt;常用语句&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;&quot;To the best of our knowledge&quot;&lt;/code&gt;&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>超分论文1-DeepLearningForSingleImage</title>
    <link href="https://loushengtao.github.io/2022/03/9409a7cc/"/>
    <id>https://loushengtao.github.io/2022/03/9409a7cc/</id>
    <published>2022-03-21T04:52:39.000Z</published>
    <updated>2022-04-14T05:06:31.128Z</updated>
    
    <content type="html"><![CDATA[<h1id="deep-learning-for-single-image-super-resolutiona-brief-review">DeepLearning for Single Image Super-Resolution：A Brief Review</h1><p>原文链接：<ahref="https://ieeexplore.ieee.org/abstract/document/8723565">DeepLearning for Single Image Super-Resolution：A Brief Review</a></p><p>本文章为原创文章，转载请说明出处：<ahref="https://loushengtao.github.io/2022/03/9409a7cc/">https://loushengtao.github.io/2022/03/9409a7cc/</a></p><h3 id="一些专有名词">一些专有名词</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">LR: Low Resolution 低分辨率<br>HR: High Resolution 高分辨率<br></code></pre></td></tr></table></figure><h2 id="概述">1 概述</h2><p>单幅图像超分辨率(SISR)是一个总所周知具有挑战性的问题，他的目的是从一个低分辨率(LR)版本种获得高分辨率(HR)输出。近年来，强大的深度学习用法已经应用于SISR，并取得了非常不错的效果。</p><p>在典型的SISR框架中，如下图所示，低分辨率LR图片模型如下：</p><p><span class="math display">\[y=(x\otimes k)\downarrow_{s}+n\tag{1}\]</span></p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage1.png"></p><p>其中，<span class="math inline">\(x\otimesk\)</span>是模糊卷积核和原图像x之间的卷积，s是具有比例因子s的下采样算子，n是独立噪声项。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage2.png"></p><p>文章中指出，迄今为止，SISR的主流算法主要分为三类：基于插值的方法、基于重构的方法以及基于学习的方法。</p><ul><li><p>基于插值的SISR方法，如双三次插值和Lanczos重采样，非常快速和简单，但是存在精度不足的问题。</p></li><li><p>基于重构的SISR方法，它们通常采用复杂的先验知识来限制可能的解空间，具有生成灵活和清晰细节的优势。然而，当比例因子增加时，许多基于重建的方法的性能迅速下降，并且这些方法通常是耗时的。</p></li><li><p>基于学习的SISR方法，也称为基于样例的方法，由于其快速的计算和出色的性能而备受关注。这些方法通常利用机器学习算法分析来自大量训练实例的LR和其对应的HR对应物之间的统计关系。</p></li></ul><h2 id="深架构sisr介绍">1.2 深架构SISR介绍</h2><h3 id="srcnn">1.2.1 SRCNN</h3><p>论文选择了SRCNN架构作为基准，SRCNN的整体架构如下图所示：</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage3.png"></p><p>如上图所示，SRCNN是一个三层的CNN，每层的卷积核大小分别为：</p><ul><li><p><spanclass="math inline">\(64\times1\times9\times9\)</span></p></li><li><p><spanclass="math inline">\(32\times64\times5\times5\)</span></p></li><li><p><spanclass="math inline">\(1\times32\times5\times5\)</span></p></li></ul><blockquote><p>这三种线性变换的作用分别是块提取、非线性映射和重建</p></blockquote><p>SRCNN的成功很大程度上归功于SRCNN的强大的学习能力。尽管SRCNN取得了成功，但仍然存在一下问题：</p><ul><li>1.SRCNN的输入是双三次(bicubic)插值的LR,它是HR的近似值。然而，这些插值具有三个缺点：<ul><li>a这些输入引入的细节平滑效应可能导致对图像结构的进一步错误估计；</li><li>b 采用内插版本作为输入非常耗时</li><li>c当下采样内核未知时，一个特定的插值输入作为原始估计是不合理的。</li></ul></li><li>2.SRCNN只是一个三层的架构，如果对模型架构进行加深，加宽并且增加拓扑结构，能否获得更好的结果？如果是，那么如何设计这种更复杂的模型？</li><li>3.损失函数中反映HR图像属性的先验项是不够的。是否可以将SISR过程的任何属性集成到CNN框架或SISR算法中？</li></ul><h3 id="espcn">1.2.2 ESPCN</h3><p>针对上述的第一个问题，即SRCNN的输入是一个双三次插值的LR问题，解决方案是在<strong>CNN架构中设计一个模块，以自适应地提高分辨率</strong>。</p><p>池化卷积和步幅卷积是基本CNN架构中常见的下采样算子。自然地，人们可以实现上采样操作，这被称作反卷积(deconvolution)或转置卷积(transposedconvolution)。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage4.png"></p><p>如图所示，给定上采样因子，反卷积层由任意插值算子(图中采用的为最邻近插值为简单起见)，和步长为1的后续卷积算子组成。</p><blockquote><p>需要注意的是，反卷积层可能无法完全恢复池化或者步幅卷积中的信息，关于反卷积层更详细的说明<ahref="https://arxiv.org/abs/1609.07009">Is the deconvolution layer thesame as a convolutional layer?</a></p></blockquote><p><strong>To the best of ourknowledge</strong>，FSRCNN是第一个使用这种正常的反卷积层从LR特征图重建HR图像的工作。如前所述，使用反卷积层主要有两个主要优点：一是实现了计算量的减少，因为只需要在网络末端增加分辨率，而不需要在其他步骤中用较大的计算量增加分辨率。二是是当下采样内核未知时，许多论文已经表明输入的不准确估计将会对最终性能产生副作用。</p><p>在使用最邻近插值进行上采样时，上采样特征中的点在每个方向都上重复了几次，这种操作是多余的。为了规避这个问题，有人提出了一种有效的亚像素卷积层，称为ESPCN<ahref="#2">2</a>。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage5.png"></p><p>ESPCN的结构如上图所示，ESPCN不是像反卷积层那样通过显示放大特征图来提高分辨率，而是扩展输出特征的通道以存储额外点以提高分辨率，然后重新排列这些点以获得通过特定映射标准的HR输出。</p><p>上面的黄色箭头是作者从零插值角度理解的亚卷积层卷积过程，而下面的黑色箭头是ESPCN原文中的具体过程，即先卷积，然后再排列。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage6.png"></p><p>上图为ESPCN原论文的整体架构，下面对具体放法进行阐述：</p><p><spanclass="math inline">\(I^{LR}\)</span>为LR图像，在新的网络架构中，对于L层组成的网络，前L-1层可以描述如下：<span class="math display">\[f^{1}(I^{LR};W_{1},b{1})=\phi(W_{1}*I^{LR}+b_{1}) \tag{1}\]</span></p><p><span class="math display">\[f^{l}(I^{LR};W_{1:l},b{1:l})=\phi(W_{l}*f^{l-1}(I^{LR})+b_{l}) \tag{2}\]</span></p><p>假设目标的通道数为<spanclass="math inline">\(c\)</span>，单个边长放大的倍数为<spanclass="math inline">\(r\)</span>，则通过卷积，会生成通道数为<spanclass="math inline">\(r^{2}c\)</span>，大小为原图大小的特征层，最后再经过特定的顺序进行排列，生成最终的HR图像。<img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage7.png"></p><p>对于最终的<spanclass="math inline">\(I^{SR}\)</span>，有公式如下：</p><p><spanclass="math display">\[I^{SR}=f^{L}(I^{LR})=\mathcal{PS}(W_{L}*f^{L-1}(I^{LR}+B_{L}))\tag{3}\]</span></p><p>其中<span class="math inline">\(\mathcal{PS}\)</span>是将形状为<spanclass="math inline">\(H\times W\times C\cdotr^{2}\)</span>的张量元素排列成形状为<span class="math inline">\(rH\timesrW\times C\)</span>的张量的一个周期性混洗算子(periodic shufflingoperator)。在数学上，该操作可以用以下方式描述：</p><p><spanclass="math display">\[\mathcal{PS}_{x,y,c}=T_{[x/r],[y/r],c\cdot r\cdotmod(y,r)+c\cdot mod(x,r)} \tag{4}\]</span></p><h3 id="vdsr基于vgg">1.2.3 VDSR——基于VGG</h3><p>在深度学习的研究中，有理论工作<a href="#3">[3]</a>表明DNN(DeepNN)深度升级网络的解空间可以通过增加其深度或者宽度来扩展。在某些情况下，为了更有效地获得更多的层次表示，许多工作主要集中在通过增加深度来获得改进。VDSR<ahref="#4">[4]</a>是SISR中第一个使用非常深的网络架构的模型。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage8.png"></p><p>对于SR的图像重建，VDSR的作者受到了Simonyan和Zisserman的启发<ahref="#5">[5]</a>。VDSR使用了d层，除了第一层和最后一层外，其他层都为相同类型：</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage9.png"></p><p>如图所示，第一层对输入图像进行操作，最后一层用于图像重建。中间的每一层使用了64个大小为<spanclass="math inline">\(3\times 3\times64\)</span>的卷积核，其中卷积核在64个通道上的<spanclass="math inline">\(3 \times 3\)</span>空间区域上操作(特征图)。</p><h3 id="drcn基于vdsr的优化">1.2.4 DRCN——基于VDSR的优化</h3><p>经过研究，有学者发现，VDSR的非线性映射部分的卷积核非常相似，为了减少参数，Kim等人进一步提出了DRCN</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage10.png"></p><p>如图所示，DRCN在非线性映射部分使用了16次相同的卷积核，同时，为了克服训练深度递归CNN的困难，DRCN采用了多重监督策略，最后的结果可以看作是16个中间结果的融合，用于融合的结果是一系列总和为1的可训练正标量。实验结果证明DRCN与VDSR有着非常相似的性能，与此同时DRCN比VDSR的参数更少。</p><h3 id="srresnet基于resnet">1.2.5 SRResNet——基于ResNet</h3><p>像VGG网络这样的简单架构很难再通过继续加深神经网络来实现效果上的优化。由何明恺等人提出的ResNet在许多任务中实现了最先进的性能。基于"skip-connections"的ResNet也被用于超分领域，被提出为SRResNet。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage11.png"></p><p>它由16个残差单元组成，每个残差单元由两个带残差学习的非线性卷积组成，同时BatchNormalization批量标准化被用于稳定训练的过程</p><h3 id="drrn基于resnet的拓扑优化">1.2.6 DRRN——基于ResNet的拓扑优化</h3><p>基于ResNet的原始残差单元，Tai等人提出了DRRN：</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage12.png"></p><p>在DRRN中，基于拓扑，原始残差单元在递归过程中重新排列形成递归快。然后，为了实现参数的缩减，每个块共享相同的参数，并且被递归的重用，例如在DRCN的单个递归卷积核中。</p><h3 id="edsr基于resnet的优化">1.2.7 EDSR——基于ResNet的优化</h3><p>EDSR是由Lee等人提出的有更好的表现的模型。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage13.png"></p><p>EDSR在整体框架上主要做了三点改进：</p><ul><li><ol type="1"><li>与之前工作中使用的残差单元相比，EDSR去除了BN的使用——BN的原始ResNet被设计用于分类，其中内部表示是高度抽象的，并且这些表示可能对BN引入的位移不敏感。对于SISR这样的图像到图像的任务，由于输入和输出是密切相关的，网络的收敛不再是一个难题，所以这种BN引入的偏移会损害最终的性能。</li></ol></li><li><ol start="2" type="1"><li>除了有规律的深度增加。EDSR还大规模增加了各层输出特征数量。为了消除训练如此宽的ResNet的困难，采用了<ahref="#6">[6]</a>提出的残差放缩技巧"Scale"。</li></ol></li><li><ol start="3" type="1"><li>SISR不同的尺度因子具有很强的联系，当训练<spanclass="math inline">\(\times3\)</span>和 <spanclass="math inline">\(\times4\)</span>尺度的模型时，EDSR的作者用预训练<spanclass="math inline">\(\times2\)</span>网络来初始化参数。这种预训练策略加快了训练速度，提高了最终成绩</li></ol></li></ul><blockquote><p><strong><em>ESDR的预训练策略的有效性意味着不同尺度的模型可以共享许多中间表示</em></strong></p></blockquote><h3 id="densesr">1.2.8 DenseSR</h3><p>除了ResNet之外，DenseNet是另一种基于跳过连接的有效架构，在DenseNet中，每一层都所有前面的层相连接，瓶颈层(通常为<spanclass="math inline">\(1\times1\)</span>卷积核，为了改变深度减少计算量)以单元核块的形式使用，以减少参数数量。有学者指出，ResNet与DenseNet不同之处在于ResNet更多的是支持功能重用，而DenseNet支持新功能探索。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage14.png"></p><p>如图所示，DenseSR在反卷积层之前进一步连接来自不同块的所有特征，实验证明这样做提高了网络的性能。</p><h3 id="mdsr不同尺度共享表示的初步探寻">1.2.9MDSR——不同尺度共享表示的初步探寻</h3><p>在EDSR不同尺度因子的预训练有效的情况下，ESDR的作者进一步提出了MSDR：</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage15.png"></p><p>如图所示，在MDSR中，用于非线性映射的卷积核在不同尺度撒谎给你共享，其中只有由于提取特征的前卷积核和最后的子像素上采样卷积是不同的。在训练MDSR期间的每次更新时，随机选择<spanclass="math inline">\(\times2\)</span>、<spanclass="math inline">\(\times3\)</span>、<spanclass="math inline">\(\times4\)</span>的小Batch，并且仅更新MDSR的对应部分。</p><h3 id="memnet">1.2.10 MemNet</h3><p>MemNet是另一种基于DenseNet的SISR模型。Tai等人提出的MemNet使用残差单元递归地替换基本的DenseNet的正常卷积块，并在不同块之间添加密集连接，如下图所示。</p><p><img src="\assets\BlogPic\超分论文1-DeepLearningForSingleImage16.png"></p><p>MemNet的作者解释说，<strong>统一区块中的局部连接层类似于短期记忆，而与先前区块的连接类似于长期记忆。</strong></p><h1 id="超分模型衡量标准">2.超分模型衡量标准</h1><h2 id="psnr">2.1 PSNR</h2><p>PSNR——Peak Signal-to-Noise Ratio 即峰值信噪比，假设都拥有<spanclass="math inline">\(N\)</span>个像素的两张图片<spanclass="math inline">\(I\)</span> 和 <spanclass="math inline">\(\hat{I}\)</span> MSE和PSNR 定义如下：</p><p><spanclass="math display">\[MSE=\frac{1}{N}||I-\hat{I}||_{F}^{2}\]</span></p><p><spanclass="math display">\[PNSR=10log_{10}^{(\frac{L^{2}}{MSE})}\]</span></p><p>其中<spanclass="math inline">\(||.||_{F}^{2}\)</span>为佛罗贝尼乌斯范数(FrobeniusNorm) 并且L的值通常为255</p><h2 id="ssim">2.2 SSIM</h2><p>SSIM——Structural SimilarityIndex，即度量结构相似性的指标。假设都拥有<spanclass="math inline">\(N\)</span>个像素的两张图片<spanclass="math inline">\(I\)</span> 和 <spanclass="math inline">\(\hat{I}\)</span> SSIM 定义如下：</p><p><spanclass="math display">\[SSIM(I,\hat{I})=\frac{2\mu_{I}\mu_{\hat{I}}+k_{1}}{\mu_{I}^{2}+\mu_{\hat{I}}^{2}+k_{1}}\cdot\frac{\sigma_{I\hat{I}}+k_{2}}{\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+k_{2}}\]</span></p><p>其中，<span class="math inline">\(\mu_{I}\)</span>和<spanclass="math inline">\(\sigma_{I}^{2}\)</span>是图片I的均值和方差，<spanclass="math inline">\(\sigma_{I\hat{I}}\)</span>是图片<spanclass="math inline">\(I\)</span>和<spanclass="math inline">\(\hat{I}\)</span>的协方差，<spanclass="math inline">\(k_{1}\)</span>和<spanclass="math inline">\(k_{2}\)</span>为常数松弛项(constant relaxtionterms)</p><h2 id="参数量">2.3 参数量</h2><p><span class="math inline">\(Number\ of\ parameters\ of\ NN\ formeasuring\ storage\ efficiency\)</span></p><p>即网络参数量，也是衡量网络模型的一个标准</p><h2 id="multadds">2.4 Mult&amp;Adds</h2><p><span class="math inline">\(Number\ of\ composite\multiply-accumulate\ operations\ for\ measuring\ computational\efficiency\)</span></p><p>顾名思义，即用于测量计算效率的复合乘法累加操作数。</p><h1 id="references">References</h1><p>[1] <ahref="https://ieeexplore.ieee.org/abstract/document/8723565">DeepLearning for Single Image Super-Resolution：A Brief Review</a></p><p><span id="2">[2] <ahref="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Shi_Real-Time_Single_Image_CVPR_2016_paper.html">Real-TimeSingle Image and Video Super-Resolution Using an EfficientSub-PixelConvolutional Neural Network</a></p><p><span id="3">[3] <ahref="https://proceedings.neurips.cc/paper/2014/hash/109d2dd3608f669ca17920c511c2a41e-Abstract.html">G.F. Montufar, R. Pascanu, K. Cho, and Y. Bengio,“On the number of linearregions of deep neural networks,” in Proceedings of the Advances inNeural Information Processing Systems, 2014, pp. 2924–2932.</a></p><p><span id="4">[4] <ahref="https://openaccess.thecvf.com/content_cvpr_2016/html/Kim_Accurate_Image_Super-Resolution_CVPR_2016_paper.html">AccurateImage Super-Resolution Using Very Deep Convolutional Networks</a></p><p><span id="5">[5] <a href="https://arxiv.org/abs/1409.1556">K.Simonyan and A. Zisserman. Very deep convolutional networks forlarge-scale image recognition. In ICLR, 2015.</a></p><p><span id="6">[6] <ahref="hhttps://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPaper/14806">C.Szegedy, S. Ioffe, V. Vanhoucke, and A. A.Alemi,“Inception-v4,inception-resnet and the impact of residualconnections on learning,” in Proceedings of the Association for theAdvancement of Artificial Intelligence, 2017, pp. 4278–4284.</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1
id=&quot;deep-learning-for-single-image-super-resolutiona-brief-review&quot;&gt;Deep
Learning for Single Image Super-Resolution：A Brief Review&lt;/h1&gt;</summary>
      
    
    
    
    
    <category term="论文" scheme="https://loushengtao.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>深度学习常用计算公式</title>
    <link href="https://loushengtao.github.io/2022/03/cfa63db/"/>
    <id>https://loushengtao.github.io/2022/03/cfa63db/</id>
    <published>2022-03-14T01:56:53.000Z</published>
    <updated>2022-03-14T05:24:30.306Z</updated>
    
    <content type="html"><![CDATA[<h2id="深度学习中经常用到的计算公式只给公式不写理由">深度学习中经常用到的计算公式，只给公式不写理由</h2><ul><li><p><code>卷积后图片大小</code></p><p>设输入图像尺寸为W,卷积核尺寸为F，步长为S，Padding为P，使用该卷积层后输出图像尺寸为NxN：</p><p><span class="math display">\[N=\frac{W-F+2P}{S}+1\]</span></p></li><li><p><code>最大池化后图片大小</code></p><p>设输入图像尺寸为W,池化核尺寸为F,步长为S，padding为P，元素步幅dilation为D,池化后输出图像大小：</p><p><spanclass="math display">\[W=\frac{W+2P-D(F-1)-1}{S}+1\]</span></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2
id=&quot;深度学习中经常用到的计算公式只给公式不写理由&quot;&gt;深度学习中经常用到的计算公式，只给公式不写理由&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;卷积后图片大小&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;设输入图像尺寸为W,卷积核尺寸为F，步长为S，Padding为P，使用</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>JPEG图片压缩原理</title>
    <link href="https://loushengtao.github.io/2022/03/9ee9d580/"/>
    <id>https://loushengtao.github.io/2022/03/9ee9d580/</id>
    <published>2022-03-10T02:46:00.000Z</published>
    <updated>2022-03-15T08:16:53.491Z</updated>
    
    <content type="html"><![CDATA[<h1 id="jpeg概述">1.JPEG概述</h1><p>JPEG是Joint Photographic ExpertsGroup的缩写，即ISO和IEC联合图像专家组，负责静态图像压缩标准的指定，这个专家组开发的算法就被称为JPEG算法，并且已经成为大家通用的标准，即JPEG标准。JPEG压缩是有损压缩,但这个损失的部分是人的视觉不容易察觉到的部分，<strong>他充分利用了人眼对计算机色彩中高频信息不敏感的特点</strong>，来大大节省了需要处理的数据信息。</p><h2 id="去除视觉上的多余信息">1.1 去除视觉上的多余信息</h2><p>由于人眼的视觉生理特性，人眼对不同频率成分有不同的敏感度</p><ul><li>如人眼含有对亮度敏感的柱状细胞1.8亿个，含有对色彩敏感的椎状细胞0.08亿个。故眼睛对亮度的敏感程度要大于对色彩的敏感程度。</li></ul><p>总体而言，一个原始图像信息，要对其进行JPEG编码，过程分两大步：</p><ul><li><ol type="1"><li>去除视觉上的多余信息，即空间冗余度</li></ol></li><li><ol start="2" type="1"><li>去除数据本身的多余信息，即结构(静态)冗余度</li></ol></li></ul><p><img src="\assets\BlogPic\JPEG图片压缩原理1.png"></p><p>如上图，除了表示图像像素的位置水平X轴和垂直Y轴以外，还有一个表示色彩值的Z轴。Z代表了三元色各个分支R/G/B的混合时所占的具体数值大小，每个像素的RGB的混合值可能都不同，但是临近的两个点的R/G/B三个值会比较接近。</p><h2 id="去除数据本身的多余信息">1.2 去除数据本身的多余信息</h2><p>利用Huffman编码，来将最后的数据用无损的方式做压缩，这个是纯数学上的处理方式。</p><h2 id="图像信号的频谱特性">1.3 图像信号的频谱特性</h2><p>不同的颜色对应着不同的频率，图像信号的频谱线一般在0-6MHz范围内，而且一幅图像内，包含了各种频率的分量。但是包含的大多数为低频频谱线，只在占图像区域比例很低的图像边缘信号中才含有高频谱线。——<strong>这是JPEG对图像压缩的理论依据</strong></p><p>具体的做法即使为：在对图像做数字处理时，可根据频谱因素分配比特数：对包含信息量大的低频谱区域分配较多的比特数，对包含信息量少的高频谱区域分配较低的比特数，而图像质量并没有可察觉的损伤，以达到数据压缩的目的。</p><h2 id="总体来说上面的几步即是">总体来说，上面的几步即是：</h2><p>如果处理的是彩色图像，JPEG算法首先将RGB分量转化成亮度分量和色差分量，同时丢失一般的色彩信息(空间分辨率减半)。然后，用DCT来进行块变换编码，舍弃高频的系数，并对余下的系数进行量化以进一步减少数据量。最后，使用RLE行程编码和Huffman编码来完成压缩任务</p><h1 id="jpeg原理详解">2.JPEG原理详解</h1><p>下面将更加详细地介绍这两步中的各个细节。</p><p>JPEG编码中主要涉及到的内容主要包括：</p><ul><li><ol type="1"><li>Color Model Conversion(色彩模型)</li></ol></li><li><ol start="2" type="1"><li>DCT(Discrete Cosine Transform 离散余弦变换)</li></ol></li><li><ol start="3" type="1"><li>重排列DCT结果</li></ol></li><li><ol start="4" type="1"><li>量化</li></ol></li><li><ol start="5" type="1"><li>RLE编码</li></ol></li><li><ol start="6" type="1"><li>范式Huffman编码</li></ol></li><li><ol start="7" type="1"><li>DC的编码</li></ol></li></ul><p><img src="\assets\BlogPic\JPEG图片压缩原理2.png"></p><h2 id="色彩空间-color-space">2.1 色彩空间 color space</h2><p>在图像处理中，为了利用人的视角特性，从而降低数据量，通常把RGB空间表示的彩色图像变换到其他色彩空间。</p><p>现在采用的色彩空间有三种：YI1，YUV，YCrCb</p><p>每一种色彩空间都产生了一种亮度分量信号和两种色度分量信号，而每一种变换使用的参数都是为了适应某种类型的显示设备</p><p><img src="\assets\BlogPic\JPEG图片压缩原理3.png"></p><h2 id="色彩深度-color-depth">2.2 色彩深度 color depth</h2><p>一幅图像是由很多个像素点组成的，存储每个像素点所用的位数叫做像素深度。对不同的图片，这个值是可以有所不同的，从而会使得图片的数据有多和少的区别。</p><p>一幅彩色图像的每个像素用RGB三个分量表示，那么一个像素共用3*8=24位表示，就说像素的深度24bit，每个像素可以是2的24次方种颜色种的一种。表示一个像素的位数越多，它能表达的颜色数目就越多。</p><h2 id="离散余弦变换dct">2.3 离散余弦变换DCT</h2><p>将图像从色彩域转换到频率域，常用的变换方法有：</p><ul><li>傅氏变换</li><li>Walsh-Hadamard沃尔什哈达码变换</li><li>正弦变换</li><li>余弦变换——应用最广</li><li>斜变换</li><li>哈尔变换</li><li>K-L变换</li></ul><h3 id="离散余弦变换预备知识">2.3.1 离散余弦变换预备知识</h3><p>二维傅里叶可分离变换可用通用的关系式来表示</p><p><spanclass="math display">\[F(u,v)=\sum_{x=0}^{M-1}f(x,y)g(x,y,u,v)\]</span></p><p><spanclass="math display">\[f(x,y)=\sum_{u=0}^{M-1}\sum_{v=0}^{N-1}F(u,v)h(x,y,u,v)\]</span></p><p>式中：<spanclass="math inline">\(x,u=0,1,2,...,M-1;y,v=0,1,2,...,N-1;\)</span>g(x,y,u,v)和h(x,y,u,v)分别称为正向变换核和反向变换核</p><p>如果满足：</p><p><spanclass="math display">\[g(x,y,u,v)=g_{1}(x,u)g_{2}(y,v)\]</span></p><p><spanclass="math display">\[h(x,y,u,v)=h_{1}(x,u)h_{2}(y,v)\]</span></p><p>则称正、反变换核是可分离的，进一步，如果<spanclass="math inline">\(g_{1}\)</span>和<spanclass="math inline">\(g_{2}\)</span>，<spanclass="math inline">\(h_{1}\)</span>和<spanclass="math inline">\(h_{2}\)</span>在函数形式上一样，则称该变换核是对称的</p><p><strong>图像变换的矩阵表示</strong></p><p>数字图像都是实数矩阵，设<spanclass="math inline">\(f(x,y)\)</span>为MxN的图像灰度矩阵，通常为了分析、推导方便，可将可分离变换写成矩阵的形式：</p><p><span class="math display">\[F=P\cdot f\cdot Q\]</span></p><p><span class="math display">\[f=P^{-1}FQ^{-1}\]</span></p><p>其中，F、f是二维矩阵<span class="math inline">\(M\timesN\)</span>的矩阵；P是<span class="math inline">\(N\cdotN\)</span>的矩阵。</p><p><spanclass="math display">\[F(u,v)=\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}P(x,u)f(x,y)Q(y,v)\]</span></p><p>式中，u=0,1,2,...,M-1，v=0,1,2,...,N-1</p><p>对于二维离散傅里叶变换，则有：</p><p><span class="math display">\[P(x,u)=g_{1}(x,u)=e^{\frac{-j2\piux}{M}}\]</span></p><p><span class="math display">\[D(y,u)=g_{2}(y,u)=e^{\frac{-j2\pivy}{N}}\]</span></p><h3 id="离散余弦变换数学原理">2.3.2 离散余弦变换数学原理</h3><p>离散余弦变换（Discrete CosineTransform，DCT）是可分离的变换，其变换核为余弦函数。DCT除了具有一般的正交变换性质外，它的变换阵的基向量能很好地描述人类语音信号和图像信号的相关特征。因此，在对语音信号、图像信号的变换中，DCT变换被认为是一种准最佳变换。</p><p><strong>一维离散余弦变换定义</strong></p><p><spanclass="math display">\[g(x,u)=C(u)\sqrt{\frac{2}{N}}cos\frac{(2x+1)u\pi}{2N}\]</span></p><p>一维DCT定义如下：设{f(x)|x=0,1,...,N-1}为离散的信号列</p><p><spanclass="math display">\[F(u)=C(u)\sqrt{\frac{2}{N}}\sum_{x=0}^{N-1}f(x)cos\frac{(2x+1)u\pi}{2N}\]</span></p><p><strong>二维离散余弦变换</strong></p><p>二维DCT正变换核为：</p><p><spanclass="math display">\[g(x,y,u,v)=\frac{2}{\sqrt{MN}}C(u)C(v)cos\frac{(2x+1)u\pi}{2M}cos\frac{(2y+1)v\pi}{2N}\]</span></p><p>式子中，x,u=0,1,2,...,M-1;y,v=0,1,2,...,N-1</p><p>二维DCT定义如下：</p><p>设f(x,y)为MxN的数字图像矩阵，则：</p><p><spanclass="math display">\[F(u,v)=\frac{2}{\sqrt{MN}}\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}f(x,y)C(u)C(v)cos\frac{(2x+1)u\pi}{2M}cos\frac{(2y+1)v\pi}{2N}\]</span></p><p>式中：x,u=0,1,2,...,M-1;y,v=0,1,2,...,N-1</p><p>综上，DCT变换的公式为：</p><p><spanclass="math display">\[F(u,v)=\frac{1}{4}C(u)C(v)[\sum_{i=0}^{7}\sum_{j=0}^{7}f(i,j)cos\frac{(2i+1)u\pi}{16}cos\frac{(2j+1)v\pi}{16}]\]</span></p><p>f(i,j)经DCT变换之后，F(0,0)是直流系数，其他为交流系数。</p><p><img src="\assets\BlogPic\JPEG图片压缩原理4.png"></p><p>上图为8x8的原始图像，将原始图像推移128，使其范围变为-128~127</p><p><img src="\assets\BlogPic\JPEG图片压缩原理5.png"></p><p>使用离散余弦变换，并四舍五入取最接近的整数</p><p><img src="\assets\BlogPic\JPEG图片压缩原理6.png"></p><p>经过以上操作，取样块便从时间域转化成了频率域的系数块。</p><p><strong>DCT将原始图像信息块转换成不同频率分量的系数集，有两个优点</strong></p><ul><li>信号常将其能力大部分集中于频率域的一个小范围内，这样一来，描述不重要的分量只需要很少的比特数。</li><li>频率域分解映射了人类视觉系统的处理过程，并允许后继的量化过程满足其灵敏度的要求。</li></ul><h2 id="量化">2.4 量化</h2><p>量化过程实际上就是对DCT系数的一个优化过程。它是利用了人眼对高频部分不敏感的特性来实现数据的大幅简化。量化为整个过程中主要的有损运算。</p><ul><li>量化过程实际上是简单地把频率领域上每个成分，除以一个对于该成分的常数，且接着四舍五入取最接近的整数。</li></ul><p><img src="\assets\BlogPic\JPEG图片压缩原理8.png"></p><p>因为人眼对亮度信号比对色差信号更敏感，因此使用了两种量化表：亮度量化值和色差量化值</p><p><img src="\assets\BlogPic\JPEG图片压缩原理9.png"></p><p>使用量化矩阵以及前面所得到的DCT系数矩阵，可以结合DC系数四舍五入得到最接近的整数</p><p><spanclass="math display">\[取整(\frac{-415}{16})=取整(-25.9375)=-26\]</span></p><p>总体而言，DCT变换实际上是空间域的<strong>低通滤波器</strong>——对Y分量采用细量化，对UV分量采用粗量化</p><h2 id="z字编排">2.5 Z字编排</h2><p>量化后的数据有很大一个特点，即是直流分量相对于交流分量来说要大，而且交流分量中含有大量的0。</p><p><img src="\assets\BlogPic\JPEG图片压缩原理7.png"></p><p>此时边可采用"Z"字形编排的方法，通过"Z"字编排，数据在交流分量的维度上会出现很多0值连续的状况。在"Z"字形编排的基础上结合行程编码，将会很大程度上降低了编码的大小。</p><h2 id="行程编码">2.6行程编码</h2><p>行程编码(Run LengthCoding)又称为"运行长度编码"或"游程编码"，它是一种无所压缩编码。</p><p>例如：5555557777733322221111111</p><p>这一串数据的一个特点是相同的内容会出现很多次，那么我们就可以用一种简化的方法来记录这一串数字，如：</p><p>(5,6) (7,5) (3,3) (3,4) (1,7)</p><h2 id="范式-huffman编码">2.7范式 Huffman编码</h2><p>范式Huffman编码(Canonical HuffmanCode)是一个按数据出现的概率进行编码的一种编码方式，很多流行的压缩方法都使用了范式哈夫曼便阿门技术，如GZIB、ZLIB、PNG、JPEG、MPEG等等。</p><p>压缩原理与下图类似：</p><p><img src="/assets/BlogPic/图像编码基础2.png"></p><h1 id="jpeg文件存储格式">3.JPEG文件存储格式</h1><p>通常我们保存的文件名后缀为jpg，但按标准来说，它是一种JFIF格式标准的文件，里面的图像压缩方式是JPEG。</p><p><code>JFIF是一个文件格式标准，JPEG是一个压缩标准，不是一个概念</code></p><p>JFIF是File InterchangeFormat的缩写，也即JPRG文件交换格式。JFIF是一个图片文件格式标准，它是一种使用JPEG图像压缩技术存储摄影图像的方法。JFIF代表了一种"通用语言"文件格式，它是专门为方便用户在不同的计算机和应用程序见传输JPEG图像而色痕迹的语言</p><p>JFIF文件格式定义中的一些内容是JPEG压缩标准未定义的，如resolution/aspectratio，color space等</p><p>参考资料：</p><p>[1] <a href="https://www.jianshu.com/p/0d0361fca2ab">JPEG图片压缩原理（一）</a></p><p>[2] <ahref="https://blog.csdn.net/baidu_38172402/article/details/105272324?ops_request_misc">离散余弦变换原理及实现</a></p><p>[3] <ahref="https://loushengtao.github.io/2022/03/f60ce146/">图像编码基础</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;jpeg概述&quot;&gt;1.JPEG概述&lt;/h1&gt;
&lt;p&gt;JPEG是Joint Photographic Experts
Group的缩写，即ISO和IEC联合图像专家组，负责静态图像压缩标准的指定，这个专家组开发的算法就被称为JPEG算法，并且已经成为大家通用的标准</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>NRF24L01详解</title>
    <link href="https://loushengtao.github.io/2022/03/2678189e/"/>
    <id>https://loushengtao.github.io/2022/03/2678189e/</id>
    <published>2022-03-07T03:10:04.000Z</published>
    <updated>2022-04-07T09:40:57.838Z</updated>
    
    <content type="html"><![CDATA[<p><link href="https://cdn.bootcss.com/highlight.js/8.0/styles/brown_paper.min.css" rel="stylesheet"></p><script src="https://cdn.bootcss.com/highlight.js/8.0/highlight.min.js"></script><script>    hljs.initHighlightingOnLoad();</script><h1 id="nrf24l01概述">1.NRF24L01概述</h1><p>  NRF24L01是一款在2.4~2.5GHz世界通用ISM(Industrial ScientificMedical)频段的单片无线收发器芯片。无限收发器包括：频率发生器、增强型SchockBurst<spanclass="math inline">\(^{TM}\)</span>模式控制器、功率放大器、晶体震荡器、调制器、解调器。</p><p><strong>输出功率、频道选择和协议的设置可以通过SPI接口进行设置</strong></p><blockquote><p>NRF24L01拥有极低的电流消耗——当工作在发射模式下发射功率为-6dBm时电流消耗为9mA，接收模式时为12.3mA。掉电模式和待机模式下电流消耗更低。</p></blockquote><h2 id="nrf24l01参考数据">1.1 NRF24L01参考数据</h2><p><img src="\assets\BlogPic\NRF24L01详解1.png"></p><h2 id="nrf24l01基本工作原理">1.2 NRF24L01基本工作原理</h2><p>处理器先将待传输数据解析为01的二进制数据，然后在传输数据时候，芯片将01以电磁波的形式发送出去(例如一个大正弦波表示1，两个小正弦波表示0)</p><p><img src="\assets\BlogPic\NRF24L01详解2.png"></p><p>芯片接收到电磁波时，再按照一定的速率进行解波，最后得到数据</p><p><strong>由此可见，发送方和接受方的速率以及功率都需一致</strong></p><p><img src="\assets\BlogPic\NRF24L01详解3.png"></p><h3 id="gfskgauss-frequency-shift-keying-fsk调制方式">GFSK(GaussFrequency Shift Keying) FSK调制方式</h3><p>  当原始数字信号在经过FSK调变送出前，加上一个高斯低通滤波器来限制调变后的信号频谱宽度，使得在通讯上能限制频谱宽度的传输以及功率的消耗。</p><p>  GFSK高斯频移键控调制是把输入数据经高斯低通滤波器预调制滤波后，再进行FSK调制的数字调制方式。它在保持恒定幅度的同时,能够通过改变高斯低通滤波器的3dB带宽对已调信号的频谱进行控制，具有恒幅包络、功率谱集中、频谱较窄等无线通信系统所希望的特性。</p><h2 id="nrf24l01工作模式">1.3 NRF24L01工作模式</h2><p>  NRF24L01可以设置为以下几种主要的模式，</p><p><img src="\assets\BlogPic\NRF24L01详解4.png"></p><h2 id="nrf24l01-不同模式下引脚功能">1.4 NRF24L01不同模式下引脚功能</h2><p><img src="\assets\BlogPic\NRF24L01详解5.png"></p><h3 id="待机模式">待机模式：</h3><p>  待机模式 I 在保证快速启动的同时减少系统平均消耗电流。在待机模式 I下，晶振正常工作。在待机模式 II 下部分时钟缓冲器处在工作模式。当发送端TX FIFO 寄存器为空并且 CE为高电平时进入待机模式II。在待机模式期间，寄存器配置字内容保持不变。</p><h3 id="掉电模式">掉电模式：</h3><p>  在掉电模式下,nRF24L01各功能关闭，保持电流消耗最小。进入掉电模式后， nRF24L01停止工作，但寄存器内容保持不变。启动时间见表格。掉电模式由寄存器中PWR_UP 位来控制。</p><h1 id="元器件">2.元器件</h1><h2 id="元器键引脚">2.1 元器键引脚</h2><p><img src="\assets\BlogPic\NRF24L01详解6.png"></p><p>NRF24L01芯片有8个引脚，分别为6个功能引脚和两个电源引脚，将其对应与STM32芯片相连接即可。</p><p><img src="\assets\BlogPic\NRF24L01详解7.png"></p><h1 id="代码以stm32为例">3.代码(以STM32为例)</h1><h2 id="预备说明">3.0 预备说明</h2><p>NRF24L01操作线 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">#define NRF24L01_CE PGout(8)    // 24L01片选信号<br>#define NRF24L01_CSN PGout(7)   // SPI片选信号<br>#define NRF24L01_IRQ PGout(6)   // IRQ主机数据输入<br></code></pre></td></tr></table></figure></p><h2 id="设置收发地址">3.1 设置收发地址</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">const u8 TX_ADDRESS[TX_ADR_WIDTH]=&#123;0x34,0x43,0x10,0x10,0x01&#125;;  //发送地址<br>const u8 RX_ADDRESS[RX_ADR_WIDTH]=&#123;0X34,0X43,0X10,0X10,0X01&#125;;  //接受地址<br></code></pre></td></tr></table></figure><h2 id="nrf24l01初始化">3.2 NRF24L01初始化</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">void NRF24L01_Init(void)<br>&#123;<br>    GPIO_InitTypeDef GPIO_InitStructure;<br>    SPI_InitTypeDef SPI_InitStructure;<br>    RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOB|RCC_APB2Periph_GPIOG,ENABLE); // 使能PB、PG时钟<br>    <br>    GPIO_InitStructure.GPIO_Pin=GPIO_Pin_7|GPIO_Pin_8;<br>    GPIO_InitStructure.GPIO_Mode=GPIO_Mode_Out_PP; // 推挽输出<br>    GPIO_InitStructure.GPIO_Speed=GPIO_Speed_50MHz;<br>    GPIO_Init(GPIOG,&amp;GPIO_InitStructure); // 初始化指定IO口<br>    GPIO_InitStructure.GPIO_Pin=GPIO_Pin_6;<br>    GPIO_InitStructure.GPIO_Mode=GPIO_Mode_IPD;  // PG6 输入<br>    GPIO_Init(GPIOG,&amp;GPIO_InitStructure);<br>    GPIO_ResetBits(GPIOG,GPIO_Pin_6|GPIO_Pin_7|GPIO_Pin_8); // PG6 7 8上拉<br>    <br>    SPI2_Init();    // 初始化SPI<br>    SPI_Cmd(SPI2,DISABLE);      // SPI外设不使能<br>    SPI_InitStructure.SPI_Direction=SPI_Direction_2Lines_FullDuplex;  <br>    SPI_InitStructure.SPI_Mode=SPI_Mode_Master;     // 设置SPI工作模式——设置为master(主机)<br>    SPI_InitStructure.SPI_DataSize=SPI_DataSize_8b;     // 8位帧结构<br>    SPI_InitStructure.SPI_CPOL=SPI_CPOL_Low;    // 时钟悬空低<br>    SPI_InitStructure.SPI_CPHA=SPI_CPHA_1Edge;  // 数据捕获于第一个时钟沿<br>    SPI_InitStructure.SPI_NSS=SPI_NSS_Soft;     //NSS信号由软件控制<br>    SPI_InitStructure.SPI_BaudRatePrescaler=SPI_BaudRatePrescaler_16;  // 定义波特率预分频值为16<br>    SPI_InitStructure.SPI_FirstBit=SPI_FirstBit_MSB;    // MSB 位开始<br>    SPI_InitStructure.SPI_CRCPolynomial=7;    //CRC值计算的多项式<br>    SPI_Init(SPI2,&amp;SPI_InitStructure);  // 初始化SPIx<br>    SPI_Cmd(SPI2,ENABLE);   // 使能SPI外设<br>    NRF24L01_CE=0;    // 使能24L01<br>    NRF24L01_CSN=1;    // SPI片选取消<br><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="写入值">3.3 写入值</h2><blockquote><p>在地址为reg的寄存器写入value</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 NRF24L01_Write_Reg(u8 reg,u8 value)    // reg为寄存器地址，value为写入的值<br>&#123;<br>    u8 status;<br>    NRF24L01_CSN=0;    // 使能SPI传输<br>    status=SPI2_ReadWriteByte(reg);   // 发送寄存器号<br>    SPI2_ReadWriteByte(value);      // 写入寄存器值<br>    NRF24L01_CSN=1;    // 禁止SPI传输<br>    return status<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>在跌至为reg的寄存器写入指定len长度的数据,pBuf为数据包</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 NRF24L01_Write_Buf(u8 reg,u8 *pBuf,u8 len)<br>&#123;<br>    u8 status,u8_ctr;<br>    NRF24L01_CSN=0;<br>    status=SPI2_ReadWriteByte(reg);<br>    for(u8_ctr=0;u8_ctr&lt;len;u8_ctr++)SPI2_ReadWriteByte(*pBuf++);<br>    NRF24L01_CSN=1;<br>    return status;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="读取值">3.4 读取值</h2><blockquote><p>对地址为reg的寄存器读取value</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 NRF24L01_Read_Reg(u8 reg)<br>&#123;<br>    u8 reg_val;<br>    NRF24L01_CSN=0;<br>    SPI2_ReadWriteByte(reg); <br>    reg_val=SPI2_ReadWriteByte(0xFF);<br>    NRF24L01_CSN=1;<br>    return(reg_val);<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>对地址为reg的寄存器读取指定长度len的value，pBuf为接受数据包</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 NRF24L01_Read_Buf(u8 reg,u8 *pBuf,u8 len)<br>&#123;<br>    u8 reg_val;<br>    NRF24L01_CSN=0;<br>    status=SPI2_ReadWriteByte(reg); <br>    for(u8_ctr=0;u8_ctr&lt;len;u8_ctr++)pBuf[u8_ctr]=SPI2_ReadWriteByte(0xFF);<br>    NRF24L01_CSN=1;<br>    return status;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="检测是否存在nrf24l01芯片">3.5 检测是否存在NRF24L01芯片</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 NERF24l01_Check(void)<br>&#123;<br>    u8 buf[5]=&#123;0xA5,0xA5,0xA5,0xA5,0xA5&#125;;<br>    u8 i;<br>    SPI2_SetSpeed(SPI_BaudRatePrescaler_4);     // spi 速度为9Mhz<br>    NRF24L01_Write_Buf(WRITE_REG_NRF+TX_ADDR,buf,5); //写入5个字节的地址<br>    NRF24L01_Read_Buf(TX_ADDR,buf,5);   // 读出写入的地址<br>    for(i=0;i&lt;5;i++) if(buf[i]!=0xA5) break;<br>    if(i!=5) return 1; // 检测到NRF24L01错误<br>    return 0;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="发送一次数据">3.6 发送一次数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 NRF24L01_TxPacket(u8 *txbuf)<br>&#123;<br>    u8 sta;<br>    SPI2_SetSpeed(SPI_BaudRatePrescaler_8);     //spi 速度为9Mhz<br>    NRF24L01_CE=0;<br>    NRF24L01_Write_Buf(WR_TX_PLOAD,txbuf,TX_PLOAD_WIDTH);   // 写数据到TX BUF<br>    NRF24L01_CE=1;<br>    while(NRF24L01_IRQ!=0);   // 等待发送完成<br>    sta=NRF24L01_Read_Reg(STATUS);     // 状态寄存器的值<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+STATUS,sta);   // 清除TX_DS<br>    if(sta&amp;MAX_TX)  // 达到最大重发次数<br>    &#123;<br>        NRF24L01_Write_Reg(FLUSH_TX,0xFF);  // 清除TX FIFO 寄存器<br>        return MAX_TX;<br>    &#125;<br>    if(sta&amp;Tx_OK)  // 发送完成<br>    &#123;<br>        return TX_OK;<br>    &#125;<br>    return 0xff;    // 由于其他原因发送失败<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="接收一次数据">3.7 接收一次数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 NRF24L01_RxPacket(u8 *txbuf)<br>&#123;<br>    u8 sta;<br>    SPI2_SetSpeed(SPI_BaudRatePrescaler_8);     //9Mhz<br>    sta=NRF24L01_Read_Reg(STATUS);  // 读取状态寄存器的值<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+STATUS,sta);  <br>    if(sta&amp;RX_OK)   // 接收到数据<br>    &#123;<br>        NRF24L01_Read_Buf(RD_RX_PLOAD,rxbuf,RX_PLOAD_WIDTH);    // 读取数据<br>        NRF24L01_Write_Buf(FLUSH_RX,0xFF);  // 清空RX FIFO寄存器<br>        return 0;<br>    &#125;<br>    return 1;   // 没收到任何数据<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="切换到发送模式">3.8 切换到发送模式</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">void NRF24L01_TX_Mode(void)<br>&#123;<br>    NRF24L01_CE=0;<br>    NRF24L01_Write_Buf(WRITE_REG_NRF+TX_ADDR,(u8*)TX_ADDRESS,TX_ADR_WIDTH);<br>    NRF24L01_Write_Buf(WRITE_REG_NRF+RX_ADDR_P0,(u8*)RX_ADDRESS,RX_ADR_WIDTH);<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+EN_AA,0x01);  // 使能通道0的自动应答<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+EN_RXADDR,0x01);   // 使能通道0的接收地址<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+SETUP_RETR,0x1A);  // 设置自动重发间隔时间  <br>    NRF24L01_Write_Reg(WRITE_REG_NRF+RF_CH,40);     // 设置RF通道为40<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+RF_SETUP,0x0F);    // 设置 TX 发射参数<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+CONFIG,0x0e);    // 配置基本工作模式的参数<br>    NRF24L01_CE=1;  //CE为高，10us后自动发送<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="切换到接收模式">3.9 切换到接收模式</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">void NRF24L01_RX_Mode(void)<br>&#123;<br>    NRF24L01_CE=0;<br>    NRF24L01_Write_Buf(WRITE_REG_NRF+RX_ADDR_P0,(u8*)RX_ADDRESS,RX_ADR_WIDTH);<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+EN_AA,0x01)；  // 使能通道0的自动应答<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+EN_RXADDR,0x01);<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+RF_CH,40);     // 设置RF通信频率<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+RX_PW_P0,RX_PLOAD_WIDTH);   // 选择通道0 的有效数据宽度<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+RF_SETUP,0x0F);    // 设置TX发射参数<br>    NRF24L01_Write_Reg(WRITE_REG_NRF+CONFIG,0x0F);   //配置基本工作模式参数接收模式<br>    NRF24L01_CE=1;  //CE为高，进入接收模式<br>&#125;<br></code></pre></td></tr></table></figure><p>[1] <a href="">nrf24l01中文手册</a></p><p>[2] <ahref="https://www.bilibili.com/video/BV1Fr4y1e7gz?spm_id_from=333.999.0.0">2.4GHz无线收发模块nRF24L0基础原理速览及在Arduino上面的使用</a></p><p>[3] <a href="">正点原子参考手册</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;link href=&quot;https://cdn.bootcss.com/highlight.js/8.0/styles/brown_paper.min.css&quot; rel=&quot;stylesheet&quot;&gt;&lt;/p&gt;
&lt;script src=&quot;https://cdn.bootcss.</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>LateX</title>
    <link href="https://loushengtao.github.io/2022/03/f679549b/"/>
    <id>https://loushengtao.github.io/2022/03/f679549b/</id>
    <published>2022-03-04T13:30:29.000Z</published>
    <updated>2022-03-30T03:12:09.671Z</updated>
    
    <content type="html"><![CDATA[<h1 id="latex公式编辑大全">LateX公式编辑大全</h1><h2 id="数学公式的插入">数学公式的插入</h2><p>将数学公式写在<code>$ $</code>之间，代表插入的是行内数学公式(通常称为行内模式)<br/>将数学公式写在<code>$$ $$</code>之间,会使公式图例成一行并强制居中(通常称为独立模式)</p><hr/><h2 id="常用符号">常用符号</h2><h3 id="运算符号">运算符号</h3><p><code>$\pm \mp \cup \cap \bullet \triangleleft \triangleright $</code></p><p><span class="math inline">\(\pm \mp \cup \cap \bullet \triangleleft\triangleright\)</span></p><p><code>$\oplus \odot \otimes \ominus \vee \wedge$</code></p><p><span class="math inline">\(\oplus \odot \otimes \ominus \vee\wedge\)</span></p><p><code>$\sum \prod \coprod \int \iint \oint$</code></p><p><span class="math inline">\(\sum \prod \coprod \int \iint\oint\)</span></p><p><code>$\geq\leq\neq\rightarrow\leftarrow\uparrow\downarrow$</code></p><p><spanclass="math inline">\(\geq\leq\neq\rightarrow\leftarrow\uparrow\downarrow\)</span></p><p><code>$\longrightarrow\longleftarrow\Rightarrow\Leftarrow\leftrightharpoons$</code></p><p><spanclass="math inline">\(\longrightarrow\longleftarrow\Rightarrow\Leftarrow\leftrightharpoons\)</span></p><p><code>$1\quad1\qquad1\ b1\;1\!1$  #latex中的空格</code></p><p><span class="math inline">\(1\quad1\qquad1\ b1\;1\!1\)</span></p><p><img src="\assets\BlogPic\LateX1.png"></p><p><code>$a \cdot b\quad a \times b$</code></p><p><span class="math inline">\(a \cdot b\quad a \times b\)</span></p><h3 id="特殊符号">特殊符号</h3><p><code>$+\infty -\infty$</code></p><p><span class="math inline">\(\infty -\infty\)</span></p><h3 id="字母符号">字母符号</h3><p><code>$\alpha\beta\gamma\delta\epsilon\zeta\eta\theta$</code></p><p><spanclass="math inline">\(\alpha\beta\gamma\delta\epsilon\zeta\eta\theta\)</span></p><p><code>$\iota\kappa\lambda\mu\nu\xi\omicron\pi$</code></p><p><spanclass="math inline">\(\iota\kappa\lambda\mu\nu\xi\omicron\pi\)</span></p><p><code>$\rho\sigma\tau\upsilon\phi\chi\psi\omega$</code><br /></p><p><spanclass="math inline">\(\rho\sigma\tau\upsilon\phi\chi\psi\omega\)</span></p><p><code>$\mathbb&#123;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#125;$</code></p><p><spanclass="math inline">\(\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZ}\)</span></p><p><code>$\mathcal&#123;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#125;$</code></p><p><spanclass="math inline">\(\mathcal{ABCDEFGHIJKLMNOPQRSTUVWXYZ}\)</span></p><h2 id="常用数学公式">常用数学公式</h2><p>上标——<code>$m^&#123;n+1&#125;$</code>——<spanclass="math inline">\(m^{n+1}\)</span></p><p>下标——<code>$m_&#123;n+1&#125;$</code>——<spanclass="math inline">\(m_{n+1}\)</span></p><p>分式——<code>$\frac&#123;n+1&#125;&#123;m+2&#125;$</code>——<spanclass="math inline">\(\frac{n+1}{m+2}\)</span></p><p>开平方——<code>$\sqrt&#123;n+1&#125;$</code>——<spanclass="math inline">\(\sqrt{n+1}\)</span></p><p>n开m次方——<code>$\sqrt&#123;m&#125;&#123;n&#125;$</code>——<spanclass="math inline">\(\sqrt[m]{n+2}\)</span></p><p>从m到n累计求和——<code>$\sum_&#123;i=m&#125;^n$</code>——<spanclass="math inline">\(\sum_{i=m}^n\)</span></p><p>从m到n累计求积——<code>$\prod_&#123;i=m&#125;^&#123;n&#125;$</code>——<spanclass="math inline">\(\prod_{i=m}^{n}\)</span></p><p>从m到n积分——<code>$\int_&#123;i=m&#125;^&#123;n&#125;$</code>——<spanclass="math inline">\(\int_{i=m}^{n}\)</span></p><p>a向量——<code>$\vec a$</code>——<span class="math inline">\(\veca\)</span></p><p>A到B的向量——<code>$\overrightarrow&#123;AB&#125;$</code>——<spanclass="math inline">\(\overrightarrow{AB}\)</span></p><p>省略号——<code>$a+b+\codots+z$</code>——<spanclass="math inline">\(a+b+\cdots+z\)</span></p><p>公式上面加上横杠——<code>$\overline&#123;m+n&#125;$</code>——<spanclass="math inline">\(\overline{m+n}\)</span></p><p>公式下面加上横杠——<code>$\underline&#123;m+n&#125;$</code>——<spanclass="math inline">\(\underline{m+n}\)</span></p><p>圆括号矩阵——<code>$\begin&#123;pmatrix&#125; 1 &amp; 2 \\ 3 &amp; 4 \\ \end&#123;pmatrix&#125;$</code></p><p>                  <span class="math inline">\(\begin{pmatrix} 1 &amp;2 \\ 3 &amp; 4 \\ \end{pmatrix}\)</span></p><p>方括号矩阵——<code>$\begin&#123;bmatrix&#125; 1 &amp; 2 \\ 3 &amp; 4 \\ \end&#123;bmatrix&#125;$</code></p><p>                  <span class="math inline">\(\begin{bmatrix} 1 &amp;2 \\ 3 &amp; 4 \\ \end{bmatrix}\)</span></p><p>花括号矩阵——<code>$\begin&#123;Bmatrix&#125; 1 &amp; 2 \\ 3 &amp; 4 \\ \end&#123;Bmatrix&#125;$</code></p><p>                  <span class="math inline">\(\begin{Bmatrix} 1 &amp;2 \\ 3 &amp; 4 \\ \end{Bmatrix}\)</span></p><p>行列式——<code>$\begin&#123;vmatrix&#125; 1 &amp; 2 \\ 3 &amp; 4 \\ \end&#123;vmatrix&#125;$</code></p><p>                  <span class="math inline">\(\begin{vmatrix} 1 &amp;2 \\ 3 &amp; 4 \\ \end{vmatrix}\)</span></p><p>范数双竖线——<code>$\begin&#123;Vmatrix&#125; 1 &amp; 2 \\ 3 &amp; 4 \\ \end&#123;Vmatrix&#125;$</code></p><p>                  <span class="math inline">\(\begin{Vmatrix} 1 &amp;2 \\ 3 &amp; 4 \\ \end{Vmatrix}\)</span></p><p>带省略号的矩阵</p><blockquote><p><code>$$</code></p><p><code>\begin&#123;pmatrix&#125;</code></p><p>   <code>1      &amp; a_1    &amp; a_1^2  &amp; \cdots &amp; a_1^n  \\</code></p><p>   <code>1      &amp; a_2    &amp; a_2^2  &amp; \cdots &amp; a_2^n  \\</code></p><p>   <code>\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\</code></p><p>   <code>1      &amp; a_m    &amp; a_m^2  &amp; \cdots &amp; a_m^n  \\</code></p><p><code>\end&#123;pmatrix&#125;</code></p><p><code>$$</code></p></blockquote><p><span class="math display">\[    \begin{pmatrix}        1      &amp; a_1    &amp; a_1^2  &amp; \cdots &amp; a_1^n  \\        1      &amp; a_2    &amp; a_2^2  &amp; \cdots &amp; a_2^n  \\        \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\        1      &amp; a_m    &amp; a_m^2  &amp; \cdots &amp; a_m^n  \\    \end{pmatrix}\]</span></p><p>带大括号的方程组</p><blockquote><p><code>$$</code></p><p><code>\left\&#123;\begin&#123;array&#125;&#123;c&#125;</code></p><p>    <code>a_1x+b_1y+c_1z=d_1 \\</code></p><p>    <code>a_2x+b_2y+c_2z=d_2 \\</code></p><p>    <code>a_3x+b_3y+c_3z=d_3</code></p><p><code>\end&#123;array&#125;\right.</code></p><p><code>$$</code></p></blockquote><p><span class="math display">\[\left\{\begin{array}{c}a_1x+b_1y+c_1z=d_1 \\a_2x+b_2y+c_2z=d_2 \\a_3x+b_3y+c_3z=d_3\end{array}\right.\]</span></p><p>函数综合嵌套</p><blockquote><p><code>$$</code></p><p><code>f\left(</code></p><p>  <code>\left[</code></p><p>    <code>\frac&#123;</code></p><p>      <code>1+\left\&#123;x,y\right\&#125;</code></p><p>    <code>&#125;&#123;</code></p><p>  <code>\left(</code></p><p>    <code>\frac&#123;x&#125;&#123;y&#125;+\frac&#123;y&#125;&#123;x&#125;</code></p><p>    <code>\right)</code></p><p>    <code>\left(u+1\right)</code></p><p>    <code>&#125;+a</code></p><p>  <code>\right]^&#123;3/2&#125;</code></p><p><code>\right)</code></p><p><code>$$</code></p></blockquote><p><span class="math display">\[f\left(    \left[        \frac{            1+\left\{x,y\right\}        }{        \left(            \frac{x}{y}+\frac{y}{x}        \right)        \left(u+1\right)        }+a    \right]^{3/2}\right)\]</span></p><p>分段函数:</p><blockquote><p><code>$$</code> <br/> <code>f(x)=\left\&#123;</code><br/><code>\begin&#123;aligned&#125;</code><br/>   <code>x+1     \quad &amp; 0&lt;x&lt;1 \\</code><br/>   <code>x^2+2   \quad &amp; 1&lt;x&lt;2 \\</code><br/>   <code>-x^5-4  \quad &amp; 2&lt;x&lt;3</code><br/><code>\end&#123;aligned&#125;</code><br/> <code>\right.</code><br/><code>$$</code></p></blockquote><p><span class="math display">\[ f(x)=\left\{\begin{aligned}x+1     \quad &amp; 0&lt;x&lt;1 \\x^2+2   \quad &amp; 1&lt;x&lt;2 \\-x^5-4  \quad &amp; 2&lt;x&lt;3\end{aligned}\right.\]</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;latex公式编辑大全&quot;&gt;LateX公式编辑大全&lt;/h1&gt;
&lt;h2 id=&quot;数学公式的插入&quot;&gt;数学公式的插入&lt;/h2&gt;
&lt;p&gt;将数学公式写在&lt;code&gt;$ $&lt;/code&gt;之间，代表插入的是行内数学公式(通常称为行内模式)&lt;br/&gt;将数学公式写在&lt;code&gt;$</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>图像编码基础</title>
    <link href="https://loushengtao.github.io/2022/03/f60ce146/"/>
    <id>https://loushengtao.github.io/2022/03/f60ce146/</id>
    <published>2022-03-04T02:03:34.000Z</published>
    <updated>2022-03-07T03:06:49.204Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像编码原因">1.图像编码原因:</h1><p>  传递数据信息时，通常相同的信息量可以通过不同大小的数据量去表示，显然小数据量去表示大信息量是效益最高的，而图像编码即是<strong>尝试用不同的表达方式以减少表示图像的数据量</strong>，对图像的压缩可以通过对图像的编码实现。</p><p><img src="/assets/BlogPic/图像编码基础1.jpg"></p><h1 id="数据压缩">2.数据压缩</h1><p>  减少表示给定信息所需要的数据量，包含不想管和重复信息的数据惩治为冗余数据。数据压缩的目的就是消除冗余数据。</p><h2 id="压缩率和相对冗余度">2.1 压缩率和相对冗余度</h2><p>  压缩率: <span class="math inline">\(C=\frac{n_{1} }{n_{2}}\)</span>,   相对冗余度:<spanclass="math inline">\(R=\frac{n_{1}-n_{2}}{n_{1}}=1-\frac{1}{C}\)</span></p><p>  其中,<spanclass="math inline">\(n_{1}\)</span>为压缩前的数据量(比特数)，<spanclass="math inline">\(n_{2}\)</span>为压缩后的数据量。</p><h2 id="静态图像冗余类型">2.2 静态图像冗余类型</h2><h3 id="编码冗余">2.2.1 编码冗余</h3><p>编码是用于表示信息实体和时间集合的符号系统(字母、数字。比特和类似的符号等)。</p><ul><li>码字:每个信息和事件(灰度值)被赋予了一个编码符号的序列(0x00-0xFF)</li><li>码长: 码字中的符号数量(8)</li><li>码本: 构成码字的所有编码符号的集合(0和1)</li></ul><p><strong>每个像素的平均比特数</strong></p><p><spanclass="math display">\[L_{avg}=\sum_{k=0}^{L-1}l(r_{k})p_{r}(r_{k})\]</span></p><p>其中<span class="math inline">\(r_{k}\)</span>为某一灰度值, <spanclass="math inline">\(p_{r}(r_{k})\)</span>为该灰度值使用的码字的码长(即所用的比特数)，根据上式可以得出<spanclass="math inline">\(L_{avg}\)</span></p><p>注:</p><ul><li>1.如果用较少的比特数表示出现概率较大的灰度级，用较多的的比特数表示概率较小的灰度级，得到的平均比特数较小。</li><li>2.如果<strong>平均比特数</strong>不能达到最小，就说明存在编码冗余。</li><li>3.冗余度越大,可压缩量越大</li></ul><p><img src="/assets/BlogPic/图像编码基础2.png"></p><ul><li>自然码平均码长: 8</li><li>变长码平均码长: 1.81</li><li>压缩率: 8/1.81 = 4.42</li><li>冗余度: 1-1/4.42 = 0.774</li></ul><p>  如上表所示，图像的像素值为0-255，可用8位自然码表示，统计图像像素值出现概率，出现概率较大的像素值用较少位数的变长码表示。</p><p>  见上表，像素值128出现概率最高,，为0.47，则其所对应变长码为1。接下来出现概率第二高的变长码概率设置为10，随后11、100、101...以此类推。</p><h3 id="视觉空间冗余">2.2.2 视觉(空间)冗余</h3><p>  在同一个图像中，相邻的两个像素点，会有很多色彩是很接近的，那么如很能在最后得到的图片中，尽量少得记录这些不需要的数据点，也即达到了压缩的效果。</p><p><strong>这便涉及到了图像信号的频谱特性</strong></p><p>  图像信号的频谱线一般在0-6MHz范围内，而且一幅图像内，包含了各种频率的分量。但包含的大多数为低频频谱线，只在占图像区域比列很低的图像边缘的信号才含有高频的谱线。</p><p>  因此具体的方法就是根据频谱因随分配比特数——<strong>对包含信息量大的低频谱区域分配较多的比特数，对包含信息量低的高频谱区域分配较少的比特数</strong>，而图像质量并没有可察觉的损失，以达到数据压缩的目的。</p><p>将原始图像的空间域转化为频谱域用到了数学上的离散余弦变换，即DCT(DiscreteCosine Transform)变换，DCT是基于傅里叶变换的一个变种。</p><p><img src="/assets/BlogPic/图像编码基础3.jpg"></p><h3 id="心理视觉冗余">2.2.3 心理视觉冗余</h3><p>  由于<strong>眼睛对所有视觉信息感受的灵敏度不同</strong>，以及人眼在<strong>正常的视觉处理过程中信息的相对重要程度不同</strong>，图像中的部分被视觉系统忽略的信息可以被当作是冗余信息去除。</p><h1 id="信息论相关">3.信息论相关</h1><h2 id="图像信息的度量">3.1图像信息的度量</h2><p>信息论中，一个具有概率P(E)的随机时间E所包含的信息量I(E)为:</p><p><spanclass="math inline">\(I(E)=log\frac{1}{P(E)}=-logP(E)\)</span></p><p><em>对数的底决定了信息单位，一般取2</em></p><h2 id="信号源">3.2 信号源</h2><p>一幅图像可以看作一个具有随机离散输出的信源，信源可以从一个有限的符号集中产生一个随机的符号序列。</p><blockquote><p>信源集  <span class="math inline">\(B=\)</span>{<spanclass="math inline">\(b_{1},b_{2},...,b_{j}\)</span>} <br/> 概率矢量  <span class="math inline">\(u=\)</span>[<spanclass="math inline">\(P\)</span>(<spanclass="math inline">\(b_{1}\)</span>),<spanclass="math inline">\(P\)</span>(<spanclass="math inline">\(b_{2}\)</span>),...,<spanclass="math inline">\(P\)</span>(<spanclass="math inline">\(b_{j}\)</span>)]<spanclass="math inline">\(^T\)</span></p></blockquote><h2 id="熵">3.3 熵</h2><h3 id="香农熵shannon-entropy">3.3.1 香农熵(Shannon Entropy)</h3><p>香农熵是用来描述信息量的多少、随机变量不确定性的度量</p><ul><li>给定一个随机变量X，有:</li></ul><p><spanclass="math display">\[p(x)=P_{r}\{X=x\},x\in\omega\]</span></p><ul><li>香农熵为:</li></ul><p><spanclass="math display">\[H(X)=-\sum_{x\in\omega}p(x)log_{2}p(x)\]</span></p><h3 id="联合熵joint-entropy">3.3.2 联合熵(Joint Entropy)</h3><p>衡量一对随机变量所包含的信息量，两个随机变量联合不确定性的度量，联合熵描述了随机变量的相关性，越小越相关(X,Y)及联合分布p(x,y)</p><p><span class="math display">\[H(X,Y)=-\sum_{x\in X}\sum_{y\inY}p(x,y)log_{2}p{x,y}\]</span></p><h3 id="条件熵-conditional-entrophy">3.3.3 条件熵 (ConditionalEntrophy)</h3><p>已知<spanclass="math inline">\(Y\)</span>随机变量的前提下，随机变量<spanclass="math inline">\(X\)</span>提供的信息量，根据：</p><p><span class="math display">\[p(x|y)=\frac{p(x,y)}{p(y)}\]</span></p><p>可以得到:</p><p><span class="math display">\[\begin{aligned}H(X|Y)&amp;=-\sum_{x\in X}\sum_{y\in Y}p(x,y)log_{2}p(x|y) \\&amp; =-\sum_{x\in X}\sum_{y\in Y}p(x,y)log_{2}p[\frac{(x,y)}{p(y)}] \\&amp;=H(X,Y)-H(Y)\end{aligned}\]</span></p><p>对于联合分布和边缘分布，把X或Y的熵称作边缘熵，于是有:</p><p><span class="math display">\[H(Y|X)=H(X,Y)-H(X)\]</span></p><h3 id="累计剩余熵cumulative-residual-entropy-cre">3.3.4累计剩余熵(Cumulative Residual Entropy, CRE)</h3><p>将香农熵定义中概率分布换成累计概率分布</p><p><span class="math display">\[\epsilon(X)=-\sum_{x\inX}P(X&gt;x)logP(X&gt;x)\]</span></p><h3 id="瑞利熵re">3.3.5 瑞利熵(RE)</h3><p>瑞利熵是香农熵的一种推广形式，又称作<spanclass="math inline">\(\alpha\)</span>熵</p><p><spanclass="math display">\[R_{\alpha}(X)=\frac{1}{1-\alpha}log\sum_{x\inX}p(x)^{a} \quad (\alpha&gt;0,\alpha \neq 1)\]</span></p><p>当<spanclass="math inline">\(\alpha\rightarrow1\)</span>，求得瑞利熵的极限为香农熵，求极限用洛必达法则即可</p><h2 id="相似性度量">3.4 相似性度量</h2><h3 id="互信息mutual-information-mi">3.4.1 互信息(Mutual Information,MI)</h3><p>互信息衡量随机变量<span class="math inline">\(X\)</span>,<spanclass="math inline">\(Y\)</span>之间的依赖程度，用来测量联合概率分布和二者完全独立时的分布之间的距离，使用KL散度(或称为相对熵)来定义</p><p><spanclass="math display">\[MI(X,Y)=\sum_{x}\sum_{y}p(x,y)=log\frac{p(x,y)}{p(x)\cdotp(y)}\]</span></p><p><strong>互信息、联合熵、边缘熵、条件熵之间有紧密的关系</strong></p><p><spanclass="math display">\[\begin{aligned}MI(x,y)&amp;=H(X)+H(Y)-H(X,Y)\\&amp;=H(X)-H(X|Y)\\&amp;=H(Y)-H(Y|X)\end{aligned}\]</span></p><p>互信息表示<span class="math inline">\(X\)</span>中包含<spanclass="math inline">\(Y\)</span>的信息的多少，也就是对称的<spanclass="math inline">\(Y\)</span>中包含<spanclass="math inline">\(X\)</span>的多少。若<spanclass="math inline">\(X\)</span>,<spanclass="math inline">\(Y\)</span>独立则<spanclass="math inline">\(I(X,Y)=0\)</span> ,若一一相关，则<spanclass="math inline">\(I(X,Y)=H(X)=H(Y)\)</span></p><h3 id="归一化互信息normalized-mutual-informationnmi">3.4.2归一化互信息(Normalized Mutual Information,NMI)</h3><p>为了解决互信息对图像部分重叠区域的敏感性，NMI应运而生</p><p><spanclass="math display">\[NMI(X,Y)=\frac{H(X)+H(Y)}{H(X,Y)}\]</span></p><h3 id="熵相关系数entropy-correlation-coefficient-ecc">3.4.3熵相关系数(Entropy Correlation Coefficient, ECC)</h3><p>可以看作为另一种归一化信息方法</p><p><spanclass="math display">\[\begin{aligned}ECC&amp;=\frac{2I(X,Y)}{H(X),+H(Y)}\\&amp;= 2-\frac{2}{NMI}\end{aligned}\]</span></p><h3 id="互累计剩余熵cross-cumulative-residual-entropycre">3.4.4互累计剩余熵(Cross Cumulative Residual Entropy,CRE)</h3><p>和互信息类似，只不过这里的熵换成了累计剩余熵</p><p><spanclass="math inline">\(CCRE(X,Y)=\epsilon(X)-E[\epsilon(Y|X)]\)</span></p><h3 id="alpha互信息alpha-mutual-information-alpha-mialpha-mi">3.4.5Alpha互信息(Alpha Mutual Information ,<spanclass="math inline">\(\alpha-MI\alpha-MI\)</span>)</h3><p>顾名思义，根据<span class="math inline">\(\alpha\)</span>熵得出<spanclass="math inline">\(\alpha\)</span>熵</p><p><span class="math display">\[D_{\alpha}=\frac{1}{\alpha-1}log\sum_{x\in X} \sum_{y\inY}p(x,y)^\alpha(p(x)p(y))^{1-\alpha}\]</span></p><h3 id="相对熵kl散度">3.4.6 相对熵(KL散度)</h3><p>相对熵也称作为KL散度，可以衡量两个分布之间的差异，<spanclass="math inline">\(p,q\)</span>是<spanclass="math inline">\(x\)</span>上的两个分布</p><p><span class="math display">\[D_{KL}(P||q)=\sump(x)log\frac{p(x)}{q(x)}\]</span></p><h3 id="交叉熵">3.4.7 交叉熵</h3><p>交叉熵是KL散度的一部分</p><p><span class="math display">\[H(p,q)=\sum_{x\inX}p(x)log(q(x))\]</span></p><h3 id="詹森香农散度js散度">3.4.8 詹森香农散度(JS散度)</h3><p>因为KL散度不对称，所以詹森提出了JS散度</p><p><spanclass="math display">\[JS(p||q)=\frac{1}{2}D_{KL}(p||\frac{p+q}{2})+\frac{1}{2}D_{KL}(q||\frac{p+q}{2}))\]</span></p><h3 id="詹森瑞利散度">3.4.9 詹森瑞利散度</h3><p>詹森香农散度与瑞利熵的结合</p><p><spanclass="math display">\[JR_{\alpha}^{\omega}(X,Y)=R_{\alpha}(Y)-\sum_{x\inX}p(x)R_{\alpha}(Y|x)\]</span></p><p>参考资料：</p><ul><li>[1] <ahref="https://www.cnblogs.com/WAoyu/p/11913581.html">图像中用到的信息论中的一些概念公式</a></li><li>[2] <ahref="https://blog.csdn.net/weixin_44586750/article/details/103016092?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%9B%BE%E5%83%8F%E7%BC%96%E7%A0%81%E5%9F%BA%E7%A1%80&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-5-103016092.pc_search_result_control_group&amp;spm=1018.2226.3001.4187">图像编码技术</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;图像编码原因&quot;&gt;1.图像编码原因:&lt;/h1&gt;
&lt;p&gt;  传递数据信息时，通常相同的信息量可以通过不同大小的数据量去表示，显然小数据量去表示大信息量是效益最高的，而图像编码即是&lt;strong&gt;尝试用不同的表达方式以减少表示图像的数据量&lt;/strong&gt;，对图像的压</summary>
      
    
    
    
    <category term="AI与编码" scheme="https://loushengtao.github.io/categories/AI%E4%B8%8E%E7%BC%96%E7%A0%81/"/>
    
    
  </entry>
  
  <entry>
    <title>MarkdownBasis</title>
    <link href="https://loushengtao.github.io/2022/03/5033dc9b/"/>
    <id>https://loushengtao.github.io/2022/03/5033dc9b/</id>
    <published>2022-03-03T07:31:15.000Z</published>
    <updated>2022-03-07T03:06:49.201Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于markdown">关于Markdown</h1><h2 id="一.斜体和粗体">一.斜体和粗体</h2><p> 1.<em>斜体</em> <code>*斜体*</code></p><p> 2.<strong>粗体</strong> <code>**粗体**</code></p><p> 3.<strong><em>加粗斜体</em></strong> <code>***加粗斜体***</code></p><p> 4.<del>删除线</del> <code>~~删除线~~</code></p><h2 id="二.分级标题">二.分级标题</h2><p> 1.一级标题 <code># 内容</code></p><p> 2.二级标题 <code>## 内容</code></p><p> 3.三级标题 <code>### 内容</code></p><p> 4.四级标题 <code>#### 内容</code></p><p> 5.五级标题 <code>##### 内容</code></p><p> 6.六级标题 <code>###### 内容</code></p><h2 id="三.超链接">三.超链接</h2><p>  []里写链接的文字,()中里写链接地址,()中的""为链接指定title属性,title属性可加可不加。title属性的效果是鼠标悬停在连接上白框中会出现指定title文字</p><p>语法:<code>[链接文字](http://blog.leanote.com/freewalk "地址")</code></p><p>例子:<code>欢迎来到[1st's Studio](https://loushengtao.github.io/ "^o^")</code></p><p>欢迎来到<a href="https://loushengtao.github.io/" title="^o^">1st'sStudio</a></p><h3 id="参考式">3.1 参考式</h3><p>  参考式超链接一般用在学术论文上，或者另一种情况，如果某一个链接在文章中多处使用，那么使用英勇的方式会非常好，它使我们对链接进行统一管理</p><p>参考式超链接分为两部分——文中的写法[链接文字][链接标记],文尾的写法[链接标记]:链接地址</p><p>语法:<code>...文本[链接文字][链接标记]...</code></p><p>  <code>[链接标记]:链接地址</code></p><p>例子:<code>一个非常优质的博客网站[1st's Studio][1]</code></p><p>  <code>[1]:https://loushengtao.github.io</code></p><p>一个非常优质的博客网站<a href="https://loushengtao.github.io">1st'sStudio</a></p><h3 id="锚点">3.2 锚点</h3><p>  网页中,锚点即为页内超链接,也就是链接本文档的某些元素，实现当前页面的跳转</p><p>注:</p><p>1.Markdown Extra 只支持再标题后插入锚点，其他地方无效</p><p>2.Leanote编辑器右侧显示效果区域暂时不支持锚点跳转,但发布成笔记或博文后支持跳转</p><p>语法:在你准备跳转到指定标题后插入锚点{标记},然后在文档的其他地方写上连接到锚点的链接</p><p>例子:<code>## 0.目录&#123;index&#125;</code></p><p>  <code>跳转到[目录](#index)</code></p><h2 id="五.列表">五.列表</h2><h3 id="无序列表">5.1 无序列表</h3><p>使用 * + - 表示无序列表</p><p>例如:</p><ul><li><p>无序列表项1 <code>* 无序列表项1</code></p></li><li><p>无序列表项2 <code>+ 无序列表项2</code></p></li><li><p>无序列表项3 <code>- 无序列表项3</code></p></li></ul><h3 id="无序列表-1">5.2 无序列表</h3><p>有序列表则使用数字接着英文句点,句点后一个空格</p><p>例如：</p><ol type="1"><li><p>有序列表1 <code>1. 有序列表1</code></p></li><li><p>有序列表2 <code>2. 有序列表2</code></p></li><li><p>有序列表3 <code>3. 有序列表3</code></p></li></ol><h3 id="定义型列表">5.3 定义型列表</h3><p>定义型列表由名词和解释组成: 一行写上定义，紧跟一行写上解释。</p><p>解释的写法: 紧跟一个缩进(Tab 四个空格)</p><dl><dt>Markdown</dt><dd><em>轻量级文本标记语言，可以转换成html、pdf等格式</em></dd></dl><p><code>Markdown</code></p><p><code>:(Tab 四个空格)*轻量级文本标记与语言，可以转换成html、pdf等格式*</code></p><h4 id="列表缩进">5.4 列表缩进</h4><p>  列表项标记通常是放在最左边, 但是其实也可以缩进, 最多三个空格,项目标记后面则一定要接着至少一个空格或制表符,并且上下两行之间不用再另外换行</p><blockquote><ul><li>轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。软泥上的青荇， 油油的在水底招摇； 在康河的柔波里，我甘心做一条水草！</li><li>那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间，沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉，在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默，沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖，不带走一片云彩。</li></ul></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">*   轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。<br>那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 <br>软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ <br>*   那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 <br>寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 <br>但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ <br>悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。<br></code></pre></td></tr></table></figure><h3 id="包含引用的列表">5.5 包含引用的列表</h3><p>如果要在列表项目中放进引用, 则&gt;就与要缩进</p><ul><li><p>阅读方法</p><blockquote><p>打开书本<br/>打开电灯</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">*   阅读方法<br><br>    &gt;<br>    打开书本&lt;br/&gt;打开电灯<br>    &gt;<br></code></pre></td></tr></table></figure><h3 id="包含代码区块的引用">5.6 包含代码区块的引用</h3><p>如果要放代码区块, 该区块就需要缩进两次,也就是八个空格或者两个制表符Tab</p><p><strong>此处暂不做演示, 原理同上, 嵌套用缩进来表示,一层嵌套一次Tab</strong></p><h2 id="引用">6.引用</h2><p>语法: 在需要被引用的文本前加上&gt;符号</p><blockquote><p>这是一个由有两段文字的引用<br/> 无意义的占行文字1<br/>无意义的占行文字2<br/> <br/> 无意义的占行文字3<br/>无意义的占行文字4<br/></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">&gt; 这是一个由有两段文字的引用&lt;br/&gt;<br>&gt; 无意义的占行文字1&lt;br/&gt;<br>&gt; 无意义的占行文字2&lt;br/&gt;<br>&gt; &lt;br/&gt;<br>&gt; 无意义的占行文字3&lt;br/&gt;<br>&gt; 无意义的占行文字4&lt;br/&gt;<br></code></pre></td></tr></table></figure><h2 id="插入图片">7.插入图片</h2><p>  Markdown中插入图片的语法为<code>![]()</code>, 其中方括号是图片描述,圆括号是图片路径, 一般来说,图片路径有三种：<br/> 1.相对路径<br/> 2.绝对路径<br/> 3.网络路径</p><p>  所谓网络路径就是直接引用网上的图片,直接复制图片地址，放在原阔后中就完事了。这种方式非常的方便,但是页存在一定的问题:<br/></p><ul><li><p>图片失效导致无法加载</p></li><li><p>打开网页后要再请求加载图片</p></li><li><p>原网站限制，如微信公众号的图片会变得不可见等</p></li></ul><p>  由于我们的博客是要部署在网站上, 部署后会生成新的文件目录,所以我们选择使用相对路径的方式。在hexo中使用文章资源文件夹需要在_config.yml文件中更改配置：</p><blockquote><p>post_asset_folder: true</p></blockquote><h3id="也可以使用html的语法格式插入图片">也可以使用html的语法格式插入图片</h3><p>语法:<code>&lt;img src="图片地址" width=宽 height=高 /&gt;</code>若无width与height,则为图片默认宽高</p><p>   <code>&lt;img src="/assets/pretty.jpg" /&gt;</code></p><p><img src="/assets/pretty.jpg" /></p><div><p>未完待续</p></div>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;关于markdown&quot;&gt;关于Markdown&lt;/h1&gt;
&lt;h2 id=&quot;一.斜体和粗体&quot;&gt;一.斜体和粗体&lt;/h2&gt;
&lt;p&gt; 1.&lt;em&gt;斜体&lt;/em&gt; &lt;code&gt;*斜体*&lt;/code&gt;&lt;/p&gt;
&lt;p&gt; 2.&lt;strong&gt;粗体&lt;/strong&gt; &lt;code</summary>
      
    
    
    
    
    <category term="Markdown" scheme="https://loushengtao.github.io/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>STM32-API</title>
    <link href="https://loushengtao.github.io/2022/03/769b363c/"/>
    <id>https://loushengtao.github.io/2022/03/769b363c/</id>
    <published>2022-03-03T07:24:30.000Z</published>
    <updated>2022-03-22T02:50:38.142Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spi简介">1.SPI简介</h1><h2 id="spi的通信协议">1.1 SPI的通信协议</h2><p>SPI(Serial PeripheralInterface)，<strong>顾名思义就是串行外围设备接口</strong>，是一种串行同步通讯协议，由一个主设备和一个或多个从设备组成，主设备启动与一个从设备的同步通讯，从而完成数据的交换。</p><p>SPI规定了两个SPI设备之间通信必须由主设备(Master)来控制次设备(Slave)。一个Master设备可以通过提供Clock以及对Slave设备进行片选(SlaveSelect)来控制多个Slave设备，SPI协议还规定Slave设备的Clodck由Master设备通过SCK管教提供给Slave设备，Slave设备本身不能产生或控制Clock，没有Clock则Slave设备不能正常工作</p><h2 id="基本工作原理概述">1.2 基本工作原理概述</h2><p>SPI接口一般由4根线组成，单向传输时3根线也可以。这四根线也是所有基于SPI的设备共有的，它们是SDI(数据输入)、SDO(数据输出)、SCLK(时钟)、CS(片选)。</p><ul><li><ol type="1"><li><strong>SDO</strong>-主设备数据输出，从设备数据输入；</li></ol></li><li><ol start="2" type="1"><li><strong>SDI</strong>-主设备数据输入，从设备数据输出；</li></ol></li><li><ol start="3" type="1"><li><strong>SCLK</strong>-时钟信号，由主设备产生</li></ol></li><li><ol start="4" type="1"><li><strong>CS</strong>-设备使能信号，由主设备控制</li></ol></li></ul><p><img src="\assets\BlogPic\STM32-API4.jpg"/></p><h1 id="spi特点">2.SPI特点</h1><h2 id="spi控制方式">2.1.SPI控制方式</h2><p>SPI采用主-从模式(Master-Slave)的控制方式。</p><p>SPI规定了两个SPI设备之间通信必须由主设备(Master)来控制次设备(Slave)。一个Master设备可以通过提供Clock以及对Slave设备进行片选(SlaveSelect)来控制多个Slave设备，SPI协议还规定Slave设备的Clock由Master设备通过SCK管教提供给Slave设备，Slave设备本身不能产生或控制Clock，没有Clock则Slave设备不能正常工作。</p><h2 id="spi传输方式">2.2.SPI传输方式</h2><p>采用同步方式(Synchronous)传输数据</p><p>Master设备会根据将要交换的数据来产生相应的时钟脉冲(ClockPulse)，时钟脉冲组成了时钟信号(ClockSignal)，时钟信号通过时钟极性(CPOL)和时钟相位(CPHA)控制着两个SPI设备间合适数据交换以及何时对接受到的数据进行采样，来保证数据在两个设备之间是同步传输的。</p><p><img src="\assets\BlogPic\STM32-API1.png"/></p><p>如上图所示，不论是主机还是从机，在发送数据的同时也接收到了数据。</p><h2 id="spi数据交换">2.3.SPI数据交换</h2><p>SPI设备间通信的一个简单概述如下</p><p><img src="\assets\BlogPic\STM32-API2.jpg"></p><ul><li><p>SSPBUF-(Synchronous Serial PortBuffer)，泛指SPI设备里面的内部缓冲区，一般在物理上是以FIFO的形式，保存传输过程的临时数据</p></li><li><p>SSPSR-(Synchronous Serail PortRegister)，泛指SPI设备里面的移位寄存器(ShiftRegitser)，它的作用是根据设置好的数据位宽(bit-width)把数据移入或者移出SSPBUF</p></li></ul><p>SPI设备间数据传输又被称为数据交换，是因为SPI协议规定一个SPI设备不能在数据通信过程中仅仅只充当一个"发送者或者"接收者(Receiver)"。在每一个Clock周期时间内，SPI都会发送并且同时接受一个bit大小的数据，相当于是这一个bit的数据被交换了，而不是单方面发送。</p><p><img src="\assets\BlogPic\STM32-API3.gif"/></p><h1 id="spi相关代码">3.SPI相关代码</h1><p>首先需要了解SPI的结构体SPI_InitTypeDef的定义 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">typedef struct<br>&#123;<br>    uint16_t SPI_Direction;<br>    uint16_t SPI_Mode;<br>    uint16_t SPI_DataSize;<br>    uint16_t SPI_CPOL;<br>    uint16_t SPI_CPHA;<br>    uint16_t SPI_NSS;<br>    uint16_t SPI_BaudRatePrescaler;<br>    uint16_t SPI_FirstBit;<br>    uint16_t SPI_CRCPolynomial;<br>&#125;SPI_InitTypeDef;<br></code></pre></td></tr></table></figure>参数说明：</p><ul><li>SPI_Direction是用来设置SPI的通信方式，可以选择为半双工，全双工以及串行发和串行收方式.</li><li>SPI_Mode用来设置SPI的主从模式，主机模式为SPI_Mode_Master,从机模式为SPI_Mode_Slave</li><li>SPI_DataSize为8位还是16位帧格式选择项，SPI_DataSize_8b或者SPI_DataSize_16b</li><li>SPI_CPOL 用来设置时钟极性。</li><li>SPI_CPHA用来设置时钟相位，也就是选择在串行同步时钟的第几个跳变沿(上升或下降)数据被采样，可以设置为第一个或者第二个跳变沿采集，SPI_CPHA_1Edge或者SPI_CPHA_2Edge</li><li>SPI_NSS 设置NSS信号由硬件(NSS管教)还是软件控制。</li><li>SPI_BaudRatePrescaler是设置SPI波特率预分频值也就是决定SPI的时钟的参数，有8个可选值。</li><li>SPI_FirstBit设置数据是MSB位在前还是LSB位在前。</li><li>SPI_CRCPolynomial是用来设置CRC校验多项式，提高通信可靠性，大于1即可。</li></ul><p>在使用SPI之前，需要对SPI进行初始化： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">SPI_InitTypeDef SPI_InitStructure;<br>SPI_InitStructure.SPI_Direction=SPI_Direction_2Lines_FullDuplex;  // 双线双向全双工<br>SPI_InitStructure.SPI_Mode=SPI_Mode_Master;     // 主机模式<br>SPI_InitStructure.SPI_DataSize=SPI_DataSize_8b;     // SPI发送接收8位帧结构<br>SPI_InitStructure.SPI_CPOL=SPI_CPOL_High;   // 串行同步时钟的空闲状态为高电平<br>SPI_InitStructure.SPI_CPHA=SPI_CPHA_2Edge;      // 第二个跳变沿数据被采样<br>SPI_InitStructure.SPI_NSS=SPI_NSS_Soft;     // NSS信号由软件控制<br>SPI_InitStructure.SPI_BaudRatePrescaler=SPI_BaudRatePrescaler_256;    //预分频256<br>SPI_InitStructure.SPI_FirstBit=SPI_FirstBit_MSB;      // 数据传输从MSB位开始<br>SPI_InitStructure.SPI_CRCPolynomial=7;     // CRC值为7<br>SPI_Init(SPI2,&amp;SPI_InitStructure);     // 根据指定的参数初始化外设SPIx寄存器<br></code></pre></td></tr></table></figure></p><p>在初始化之后，接下来便是使能SPI通信，假设我们使能SPI2，具体的方法是：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">SPI_Cmd(SPI2,ENABLE);   // 使能SPI外设<br></code></pre></td></tr></table></figure></p><p>接下来便可以使用SPI传输数据，固件库提供的发送函数以及接收函数原型为：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">void SPI_I2S_SendData(SPI_TypeDef* SPIx,uint16_t Data);<br>uint16_t SPI_I2S_ReceiveData(SPI_TypeDef* SPIx);<br></code></pre></td></tr></table></figure>第一个函数很好理解，即往SPIx数据寄存器里写入数据Data，从而实现发送。第二个函数就是从SPIx数据寄存器读出接收到的数据</p><p>在SPI传输数据过程中，我们经常要判断数据是否传输完成，发送区是否为空等等状态，这是通过函数SPI_I2S_GetFlagStatus实现的：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">SPI_I2S_GetFlagStatus(SPI2,SPI_I2S_FLAG_RXNE);<br></code></pre></td></tr></table></figure></p><p>利用上述函数，可以封装一个读写的API，即SPIx_ReadWriteByte函数，函数原型为：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">u8 SPIx_ReadWriteByte(u8 TxData)<br>&#123;<br>    u8 retry=0;<br>    while(SPI_I2S_GetFlagStatus(SPI2,SPI_I2S_FLAG_TXE)==RESNET)<br>    &#123;<br>        retry++;<br>        if(retry&gt;200) return 0;<br>    &#125;<br>    SPI_I2S_SendData(SPI2,TxData);<br>    retry=0<br>    while(SPI_I2S_GetFlagStatus(SPI2,SPI_I2S_FLAG_TXE)==RESNET)<br>    &#123;<br>        retry++;<br>        if(retry&gt;200) return 0;<br>    &#125;<br>    return SPI_I2S_ReceiveData(SPI2);  // 返回通过SPIx最近接收的数据<br>&#125;<br></code></pre></td></tr></table></figure></p><p>其作用是往SPIx发送缓冲区写入数据的同时可以读取SPIx接收缓冲区中的数据。</p><p>那么为什么可以如此实现呢，这需要我们对SPI的框架有所了解。</p><p><img src="\assets\BlogPic\STM32-API5.png"></p><p>从框图可以看出SPI有两个缓冲区，一个用于写入(发送缓冲区)，一个用于读取(接收缓冲区)。对数据的寄存器执行写操作时，数据将写入发送缓冲区，从数据寄存器执行读取时，将返回接收缓冲区中的值。这样写并不会出现读到的数据等于发送的数据的情况。</p><p>参考资料：</p><p>[1] <ahref="https://blog.csdn.net/Firefly_cjd/article/details/51935079?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=STM32%20SPI&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-6-51935079.142%5Ev2%5Epc_search_result_control_group,143%5Ev4%5Econtrol&amp;spm=1018.2226.3001.4187">STM32SPI详解</a></p><p>[2] <a href="">正点原子STM32F1开发指南(精英版-库函数版)</a></p><p>[3] <ahref="https://blog.csdn.net/weixin_39664998/article/details/109915670?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164788150016780265495983%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=164788150016780265495983&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-8-109915670.142%5Ev2%5Epc_search_result_control_group,143%5Ev4%5Econtrol&amp;utm_term=SPI%E4%B8%BA%E4%BB%80%E4%B9%88%E5%85%88%E5%8F%91%E9%80%81%E5%AF%84%E5%AD%98%E5%99%A8%E5%8F%B7%E5%86%8D%E5%86%99%E5%80%BC&amp;spm=1018.2226.3001.4187">SPI读取不同长度 寄存器_STM32硬件SPI主从通信实例</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;spi简介&quot;&gt;1.SPI简介&lt;/h1&gt;
&lt;h2 id=&quot;spi的通信协议&quot;&gt;1.1 SPI的通信协议&lt;/h2&gt;
&lt;p&gt;SPI(Serial Peripheral
Interface)，&lt;strong&gt;顾名思义就是串行外围设备接口&lt;/strong&gt;，是一种串行</summary>
      
    
    
    
    <category term="STM32" scheme="https://loushengtao.github.io/categories/STM32/"/>
    
    
  </entry>
  
  <entry>
    <title>HEVC</title>
    <link href="https://loushengtao.github.io/2022/03/a810a1d/"/>
    <id>https://loushengtao.github.io/2022/03/a810a1d/</id>
    <published>2022-03-02T16:28:43.000Z</published>
    <updated>2022-03-07T03:06:49.195Z</updated>
    
    <content type="html"><![CDATA[<h2 id="参考文章链接">参考文章链接：</h2><p>https://www.cnblogs.com/DwyaneTalk/p/5711333.html</p><p>https://www.kancloud.cn/digest/hevc-fred/181909</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;参考文章链接&quot;&gt;参考文章链接：&lt;/h2&gt;
&lt;p&gt;https://www.cnblogs.com/DwyaneTalk/p/5711333.html&lt;/p&gt;
&lt;p&gt;https://www.kancloud.cn/digest/hevc-fred/181909&lt;/</summary>
      
    
    
    
    <category term="科研" scheme="https://loushengtao.github.io/categories/%E7%A7%91%E7%A0%94/"/>
    
    
  </entry>
  
  <entry>
    <title>HEXO相关操作</title>
    <link href="https://loushengtao.github.io/2022/03/a84987e1/"/>
    <id>https://loushengtao.github.io/2022/03/a84987e1/</id>
    <published>2022-03-02T02:15:59.000Z</published>
    <updated>2022-03-07T03:06:49.192Z</updated>
    
    <content type="html"><![CDATA[<p>本博客记录了HEXO的各种操作：</p><h2 id="创建新博客流程">创建新博客流程：</h2><h3 id="在本地创建新博客">1.在本地创建新博客</h3><p>在git bash中输入命令： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;新博客名字&quot;</span><br></code></pre></td></tr></table></figure> 即可在本地创建 新博客名字.md文件 更多信息: <ahref="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="在本地服务器上测试">2.在本地服务器上测试</h3><p>在git bash中输入命令： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>打开本地服务器，可以简单预览，ctrl+c 关闭本地服务器 更多信息: <ahref="https://hexo.io/docs/server.html">Server</a></p><h3 id="生成本地静态文件">3.生成本地静态文件：</h3><p>在git bash中输入命令： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure> 生成本地静态文件</p><p>更多信息: <ahref="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="远程仓库部署">4.远程仓库部署</h3><p>在生成静态文件之后，需要将其链接到远程服务器 在git bash中输入命令：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure></p><p>更多信息: <ahref="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本博客记录了HEXO的各种操作：&lt;/p&gt;
&lt;h2 id=&quot;创建新博客流程&quot;&gt;创建新博客流程：&lt;/h2&gt;
&lt;h3 id=&quot;在本地创建新博客&quot;&gt;1.在本地创建新博客&lt;/h3&gt;
&lt;p&gt;在git bash中输入命令： &lt;figure class=&quot;highlight bash</summary>
      
    
    
    
    
  </entry>
  
</feed>
